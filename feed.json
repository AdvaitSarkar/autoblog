{
    "version": "https://jsonfeed.org/version/1",
    "title": "Talking about papers",
    "description": "",
    "home_page_url": "https://advaitsarkar.github.io/autoblog",
    "feed_url": "https://advaitsarkar.github.io/autoblog/feed.json",
    "user_comment": "",
    "author": {
        "name": "TAP Communications"
    },
    "items": [
        {
            "id": "https://advaitsarkar.github.io/autoblog/colorful-code-makes-programmers-lives-easier-evidence-from-eye-tracking-research.html",
            "url": "https://advaitsarkar.github.io/autoblog/colorful-code-makes-programmers-lives-easier-evidence-from-eye-tracking-research.html",
            "title": "Colorful Code Makes Programmers&#x27; Lives Easier: Evidence from Eye-Tracking Research",
            "summary": "Abstract This article examines the impact of syntax highlighting on program comprehension, breaking down the results of an empirical study&hellip;",
            "content_html": "<h2 id=\"abstract\">Abstract</h2>\n<p>This article examines the impact of syntax highlighting on program comprehension, breaking down the results of an empirical study published in 2015. Using eye-tracking technology and controlled experiments, researchers discovered that syntax highlighting significantly improves code comprehension speed, with a more pronounced effect among novice programmers. The findings suggest that visual cues in programming environments may reduce cognitive load and improve programming efficiency.</p><p><strong>Reference:</strong> Sarkar, A. (2015). The impact of syntax colouring on program comprehension. In Proceedings of the 26th Annual Conference of the Psychology of Programming Interest Group (PPIG 2015) (pp. 49–58).</p><h2 id=\"colorful-code-what-is-syntax-highlighting\">Colorful Code: What is Syntax Highlighting?</h2>\n<p>Most programmers wouldn’t dream of writing code without their editor’s familiar kaleidoscope of colors illuminating different parts of their syntax. For instance, keywords might be colored in bold blue, strings in gentle green, comments in muted gray. This coloring is so deeply ingrained in modern programming that many developers would feel lost without it. But while the value of such coloring is intuitively understood by programmers, there has not been a lot of scientific evidence that syntax highlighting actually helps programmers understand code more efficiently.</p><p>“Syntax colouring, commonly known as syntax highlighting, is a feature of some text editors which colours lexical tokens in source code text according to a certain categorisation,” explains the research paper published by the University of Cambridge. It’s essentially a visual aid that makes different parts of program code easier to distinguish, like coloring different grammatical elements in sentences.</p><h2 id=\"syntax-highlighting-significantly-speeds-up-code-comprehension-tasks\">Syntax Highlighting Significantly Speeds Up Code Comprehension Tasks</h2>\n<p>The research team conducted a carefully designed experiment using eye-tracking technology to precisely measure how programmers interact with code. Ten graduate computer science students with varying levels of programming experience were asked to mentally execute Python functions and determine their outputs. Each participant completed pairs of nearly identical programming tasks - one with syntax highlighting and one without.</p><p>The results were clear and statistically significant: syntax highlighting reduced task completion time by a median of 8.4 seconds. That might not sound dramatic for a single small code snippet, but consider how those seconds accumulate over thousands of interactions with code throughout a programmer’s day.</p><p>“Task completion times for highlighted versions of the tasks were significantly lower,” the study reports. This finding confirms what many programmers have intuitively felt but couldn’t necessarily prove - that colorful code is genuinely easier to work with.</p><h2 id=\"more-experienced-programmers-benefit-less-from-syntax-coloring\">More Experienced Programmers Benefit Less From Syntax Coloring</h2>\n<p>Interestingly, the research uncovered an inverse relationship between programming experience and the benefits of syntax highlighting. The researchers found “that programming experience was negatively correlated with time advantage. It appears that syntax highlighting improves program comprehension speed to a greater extent in novice programmers than in experienced programmers.”</p><p>This suggests that as programmers gain expertise, they develop mental models and pattern recognition abilities that partially compensate for the lack of visual cues. However, the researchers note this effect might be related to the brevity of the experimental tasks, suggesting that “repeating the study with longer programs may reveal that experienced programmers stand to gain just as much as less experienced programmers.”</p><h2 id=\"how-visual-attention-reveals-the-mental-process-of-programming\">How Visual Attention Reveals The Mental Process of Programming</h2>\n<p>Perhaps the most intriguing findings came from analyzing where programmers were looking when reading code. The eye-tracking data revealed that syntax highlighting significantly reduced what researchers called “context switches” - instances where programmers had to look back at the input values while working through the code.</p><p>“Our results show that the need to be reminded of the input values was significantly greater when the code was not highlighted,” the paper states. This observation provides a window into the mental processes happening during code comprehension.</p><p>The researchers propose a compelling explanation: “it is plausible that the mental overhead required to process and understand plain code is greater than the mental overhead required to process highlighted code, since highlighted code contains additional semantic richness by virtue of the colours of the tokens.”</p><h2 id=\"syntax-coloring-may-actually-free-up-mental-resources-during-programming\">Syntax Coloring May Actually Free Up Mental Resources During Programming</h2>\n<p>When programming without syntax highlighting, participants needed to work harder to track what each element in the code was doing. This additional mental burden appears to push other important information (like input values) out of working memory, forcing programmers to constantly check back to remind themselves of these details.</p><p>The research team hypothesizes “that syntax highlighting improves the ability of the programmer to mentally retain the state of the execution, and that highlighted code incurs a lower mental comprehension overhead.”</p><p>In some particularly striking cases, the eye-tracking data suggested programmers could almost ignore highlighted keywords entirely - as if their brain could process them peripherally without direct focus. “In some cases, the eye-tracking data suggested that the participants were able to ignore highlighted keywords entirely, as though perceiving them peripherally was enough to incorporate their semantics into the computation.”</p><h2 id=\"programming-editors-should-continue-to-prioritize-visual-comprehension-aids\">Programming Editors Should Continue to Prioritize Visual Comprehension Aids</h2>\n<p>While this study focused specifically on syntax highlighting, it points to broader implications about how visual presentation affects our ability to comprehend complex information. The findings suggest that programming environments should continue to evolve with visual aids that reduce cognitive load and make code easier to understand.</p><p>For novice programmers and educators, these findings are particularly relevant. Making programming more visually accessible through syntax highlighting and other visual cues may significantly flatten the learning curve for beginners struggling to grasp programming concepts.</p><p>The next time you open your code editor and see that familiar splash of colors, you can appreciate that those highlights aren’t just pretty decoration. They’re actually helping your brain process information more efficiently - a small but meaningful boost to your programming productivity.</p><h2 id=\"references\">References</h2>\n<p>Sarkar, A. (2015). The impact of syntax colouring on program comprehension. In Proceedings of the 26th Annual Conference of the Psychology of Programming Interest Group (PPIG 2015) (pp. 49–58).</p>",
            "author": {
                "name": "TAP Communications"
            },
            "tags": [
            ],
            "date_published": "2025-04-08T10:53:47+01:00",
            "date_modified": "2025-04-08T10:56:53+01:00"
        },
        {
            "id": "https://advaitsarkar.github.io/autoblog/uncertainty-in-data-visualization-can-be-controlled-with-draggable-error-bars.html",
            "url": "https://advaitsarkar.github.io/autoblog/uncertainty-in-data-visualization-can-be-controlled-with-draggable-error-bars.html",
            "title": "Uncertainty in Data Visualization Can Be Controlled with Draggable Error Bars",
            "summary": "Abstract This article explains how a new direct-manipulation interface allows users to control uncertainty in data visualizations through draggable error&hellip;",
            "content_html": "<h2 id=\"abstract\">Abstract</h2>\n<p>This article explains how a new direct-manipulation interface allows users to control uncertainty in data visualizations through draggable error bars. Breaking down the results from a 2015 paper, it demonstrates how this intuitive interface enables users to make informed decisions about the trade-offs between accuracy and computational resources. The research shows that users can spontaneously discover and correctly use the interface, with their behavior adapting based on computation time constraints.</p><p><strong>Reference:</strong> Sarkar, A., Blackwell, A. F., Jamnik, M., &amp; Spott, M. (2015). Interaction with uncertainty in visualisations. In Proceedings of the 17th Eurographics/IEEE VGTC Conference on Visualization (EuroVis 2015). <a href=\"https://doi.org/10.2312/eurovisshort.20151138\">https://doi.org/10.2312/eurovisshort.20151138</a></p><h2 id=\"why-uncertainty-in-data-visualization-matters\">Why uncertainty in data visualization matters</h2>\n<p>When working with massive datasets, a critical challenge emerges: how can analysts interact with data that’s simply too large to process completely in real time? A clever solution has been developing in recent years - approximate computation techniques that provide fast results with quantifiable error bounds. These techniques are gaining traction, but they introduce a new problem: how do users interact with and understand the uncertainty these approximations create?</p><p>“With the emergence of approximate computation techniques, we now have sources of uncertainty that make a trade-off between accuracy and time/space resources,” notes the paper from the 2015 Eurographics Conference on Visualization. This represents a fundamental shift in how we think about uncertainty in data visualization.</p><p>Traditionally, uncertainty has been treated as a fixed property of data - something inherent that we simply need to represent. But with new approximate computation techniques, uncertainty becomes something that can be manipulated and controlled, just like any other aspect of a visualization.</p><h2 id=\"draggable-error-bars-offer-an-intuitive-way-to-control-uncertainty\">Draggable error bars offer an intuitive way to control uncertainty</h2>\n<p>The paper introduces a novel solution: draggable error bars. This direct-manipulation interface allows users to literally grab and adjust the level of uncertainty they’re willing to accept in a visualization.</p><p>The interface is simple. Error bars represent the uncertainty in data points, and users can drag these bars to reduce uncertainty. When dragging, a horizontal indicator appears, showing the estimated time required for recomputation. This “resource cost estimation bar” is crucial - it helps users decide whether the increased accuracy is worth the computational cost.</p><p>“When dragging, a horizontal indicator bar appears, visualising the estimated duration of recomputation,” the paper explains. “This ‘resource cost estimation bar’ is an essential component of the interface, as it allows the user to judge whether they are willing to invest their resources (in this case, time) in exchange for an improvement in accuracy.”</p><p>Upon releasing the mouse button, the recomputation begins. The cost estimation indicator shrinks as the computation progresses, and the data point and error bars move to their newly accurate positions.</p><p>This interface can be applied to various types of charts, including scatterplots, bar charts, and line graphs. It works with multiple approximate computation techniques like sampling, sketching, and online aggregation.</p><h2 id=\"people-can-spontaneously-discover-how-to-use-the-interface\">People can spontaneously discover how to use the interface</h2>\n<p>But does this interface actually work for users? To find out, the researchers conducted a web-based study with 39 participants.</p><p>The results were encouraging. When asked to reduce the uncertainty associated with a point on a plot, 87% of participants successfully discovered the drag operation without any instructions. The median discovery time was just 19.3 seconds. This suggests the interface aligns well with users’ intuitive expectations about how to manipulate uncertainty.</p><p>“From this we conclude that the interface corresponds well with users’ prior assumptions about how one might manipulate uncertainty in a visualisation, i.e., it is intuitive,” states the paper.</p><h2 id=\"users-make-strategic-decisions-about-uncertainty-based-on-computation-time\">Users make strategic decisions about uncertainty based on computation time</h2>\n<p>After being given a full explanation of the interface, participants were asked to perform 30 comparison tasks, each involving two data points with error bars. Although it was always possible to give a reasonable interpretation without interacting with the error bars, 77% of participants chose to use drag operations.</p><p>Some participants (13 out of 39) used drag operations in all 30 tasks, averaging 2.53 drags per task. On average, they reduced uncertainty by 67.6% per drag. This demonstrates that participants found value in manipulating uncertainty rather than just accepting it as a fixed property.</p><p>What’s particularly interesting is how participants adapted their behavior based on recomputation time. There was a clear negative correlation between maximum recompute time and uncertainty reduced per drag per task. In other words, when recomputation was expensive (time-consuming), participants preferred to make multiple small adjustments rather than one large one.</p><p>“This corresponds to behaviour observed in our pilot studies where participants preferred to make multiple small drags if recomputation was expensive,” the paper notes.</p><h2 id=\"the-future-of-interactive-uncertainty-visualization-looks-promising\">The future of interactive uncertainty visualization looks promising</h2>\n<p>The implications of this research extend beyond just this specific interface. As approximate computation becomes more common in data analysis, interfaces that allow direct manipulation of uncertainty will become increasingly important.</p><p>This research demonstrates that users can understand and effectively use such interfaces. They can make informed decisions about the trade-offs between accuracy and computational resources, adapting their behavior based on these trade-offs.</p><p>The study shows a path forward for interactive visualization of large datasets. Instead of treating uncertainty as an undesirable but unavoidable aspect of data visualization, we can embrace it as a parameter that users can control.</p><p>“Our study provides evidence that the representation of required computational resources modulates interaction as intended, allowing skilled users to modify their usage to achieve the resource/accuracy tradeoff that suits their needs,” concludes the paper.</p><p>For data scientists and analysts working with increasingly large datasets, this approach offers a promising new way to interact with data. Rather than waiting for complete, exact computations or accepting highly uncertain approximations, users can actively participate in deciding what level of uncertainty is acceptable for their specific needs.</p><p>This represents a shift from passive consumption of visualizations to active engagement with the underlying computational processes - a shift that could make large-scale data analysis more accessible and effective.</p><h2 id=\"references\">References</h2>\n<p>Sarkar, A., Blackwell, A. F., Jamnik, M., &amp; Spott, M. (2015). Interaction with uncertainty in visualisations. In Proceedings of the 17th Eurographics/IEEE VGTC Conference on Visualization (EuroVis 2015). <a href=\"https://doi.org/10.2312/eurovisshort.20151138\">https://doi.org/10.2312/eurovisshort.20151138</a></p>",
            "author": {
                "name": "TAP Communications"
            },
            "tags": [
            ],
            "date_published": "2025-04-08T10:41:40+01:00",
            "date_modified": "2025-04-08T10:43:57+01:00"
        },
        {
            "id": "https://advaitsarkar.github.io/autoblog/bike-sharing-patterns-reveal-urban-mobility-secrets-across-global-cities.html",
            "url": "https://advaitsarkar.github.io/autoblog/bike-sharing-patterns-reveal-urban-mobility-secrets-across-global-cities.html",
            "title": "Bike Sharing Patterns Reveal Urban Mobility Secrets Across Global Cities",
            "summary": "Abstract This article explores how analyzing bike sharing data from online maps can reveal fascinating patterns in urban mobility across&hellip;",
            "content_html": "<h2 id=\"abstract\">Abstract</h2>\n<p>This article explores how analyzing bike sharing data from online maps can reveal fascinating patterns in urban mobility across multiple cities worldwide. Based on research comparing bike usage patterns in ten cities, the study uncovers how different-sized systems share surprising similarities despite geographical and cultural differences. The full paper “Comparing Cities’ Cycling Patterns Using Online Shared Bicycle Maps” by Sarkar, Lathia, and Mascolo provides insights that could help design better bike sharing systems for cities everywhere.</p><p><strong>Reference:</strong> Sarkar, A., Lathia, N., &amp; Mascolo, C. (2015). Comparing Cities’ Cycling Patterns Using Online Shared Bicycle Maps. Transportation, 42(4), 541-559. DOI: 10.1007/s11116-015-9599-9</p><h2 id=\"online-bike-maps-hold-treasure-troves-of-urban-mobility-data\">Online Bike Maps Hold Treasure Troves of Urban Mobility Data</h2>\n<p>The humble bike station map – a digital tool most cyclists check quickly before deciding where to pick up or drop off their shared bicycle – contains multitudes. These online maps, designed primarily to show available bikes and parking slots, can capture the pulse of city mobility when monitored over time.</p><p>Researchers have discovered that regularly collecting data from these maps allows for deep analysis of urban cycling trends without requiring access to proprietary system data. The study analyzed 4.5 months of data from 10 different bike sharing systems spanning 996 stations across 6 countries, creating a dataset of over 100 million samples.</p><p>“Bicycle sharing systems are increasingly being deployed in urban areas around the world, alongside online maps that disclose the state (i.e., location, number of bicycles/number of free parking slots) of stations in each city,” notes the study. This proliferation of systems provides a unique opportunity to compare mobility patterns across diverse urban environments.</p><h2 id=\"small-bike-systems-act-alike-while-large-systems-show-unique-patterns\">Small Bike Systems Act Alike While Large Systems Show Unique Patterns</h2>\n<p>Perhaps the most surprising finding from the research challenges conventional wisdom about bike sharing systems. While previous studies examining individual cities had suggested that each city has entirely unique usage patterns, this cross-city comparison revealed something different: small systems tend to behave similarly regardless of geography.</p><p>“While an aggregate comparison supports the view of cities having unique usage patterns, results of applying unsupervised learning to the temporal data shows that, instead, only the larger systems display heterogeneous behaviour, indicating that many of these systems share intrinsic similarities,” the paper states.</p><p>When researchers applied clustering techniques to analyze station behavior across all cities, they discovered that stations tend to fall into three main behavioral categories regardless of which city they’re in:</p><ol>\n<li>“Morning sink, daytime source” stations that accumulate bikes in the morning and empty throughout the day</li>\n<li>“Morning source, daytime sink” stations that empty in the morning and fill up during the day  </li>\n<li>“Flat” stations with relatively consistent occupancy throughout the day</li>\n</ol>\n<p>Interestingly, the smaller systems (like those in Girona, Spain and João Pessoa, Brazil) consisted almost entirely of “flat” stations with similar behavior patterns. Only in larger systems like London and Barcelona did significant heterogeneity appear.</p><h2 id=\"geography-shapes-cycling-patterns-in-predictable-ways\">Geography Shapes Cycling Patterns in Predictable Ways</h2>\n<p>The geographical distribution of these station types tells a compelling story about urban mobility. In London, the clustering revealed a concentric pattern with “morning sink” stations concentrated in the center, surrounded by layers of “flat” stations, with “morning source” stations on the periphery.</p><p>“This reflects a morning surge of bicycles from outside the centre moving inwards, and a slow outwards flow over the course of the day,” explains the paper. This pattern suggests commuter behavior, with people cycling into the city center for work in the morning and returning to residential areas in the evening.</p><p>Barcelona’s pattern reflects a different geographical reality. “Barcelona’s morning sink stations run through the city centre and spread out along the coast, and the morning source stations are spread out over the rest of the city,” the study found. “This map corresponds well with Barcelona’s elevation; it is in a hilly region and the placement of the ‘sink’ stations corresponds to lower elevations, while the ‘source’ stations are at higher elevations.”</p><p>This pattern illustrates a natural tendency that cyclists around the world can relate to: people prefer riding downhill rather than uphill.</p><h2 id=\"bike-availability-is-relatively-stable-in-most-cities\">Bike Availability Is Relatively Stable in Most Cities</h2>\n<p>Another aspect of the research involved predicting station occupancy. The researchers tested various prediction models to forecast how many bicycles would be available at stations at different time horizons (6, 12, 24, and 48 minutes in the future).</p><p>Surprisingly, a simple “static model” that assumes the current number of bikes will remain unchanged outperformed more sophisticated approaches like neural networks and decision tree ensembles in most cases. This suggests that for many stations, occupancy levels change relatively slowly and predictably.</p><p>However, prediction accuracy varied based on system size. “For the larger systems, prediction errors for the 2-minute series are almost identical to those of the 6-minute series. However, for the smaller systems, a variety of differences is observed,” the research notes.</p><p>The study also found that prediction models for larger systems remained accurate even when using older training data, while smaller systems required more recent data for accurate predictions. This suggests that usage patterns in larger systems are more stable over time, despite being more spatially diverse.</p><h2 id=\"bike-sharing-data-can-improve-urban-transportation-planning\">Bike Sharing Data Can Improve Urban Transportation Planning</h2>\n<p>These findings have important implications for managing existing bike sharing systems and planning new ones. Understanding which stations act as “sinks” or “sources” at different times can help optimize bicycle redistribution, a perennial challenge for bike sharing systems.</p><p>“Clustering methodologies such as ours could inform the planning of efficient redistribution schemes, by categorising areas of cities as ‘sinks’ or ‘sources’, or by identifying optimal times for triggering the dispatch of redistribution vehicles based on the aggregate occupancy behaviour,” the paper suggests.</p><p>For cities planning new bike sharing deployments, the research provides insights into how system size affects station behavior. Smaller systems tend toward homogeneity, while heterogeneity emerges with scale. This knowledge could help cities better anticipate how their systems will function as they grow.</p><p>The research demonstrates that there’s tremendous value hidden in online bike maps. By continuously monitoring them, patterns emerge that can help improve urban mobility and make bike sharing systems more efficient and user-friendly.</p><h2 id=\"references\">References</h2>\n<p>Sarkar, A., Lathia, N., &amp; Mascolo, C. (2015). Comparing Cities’ Cycling Patterns Using Online Shared Bicycle Maps. Transportation, 42(4), 541-559. DOI: 10.1007/s11116-015-9599-9</p>",
            "author": {
                "name": "TAP Communications"
            },
            "tags": [
            ],
            "date_published": "2025-04-08T10:33:30+01:00",
            "date_modified": "2025-04-08T10:37:37+01:00"
        },
        {
            "id": "https://advaitsarkar.github.io/autoblog/making-data-analytics-visual-how-end-user-programming-breaks-expertise-barriers.html",
            "url": "https://advaitsarkar.github.io/autoblog/making-data-analytics-visual-how-end-user-programming-breaks-expertise-barriers.html",
            "title": "Making Data Analytics Visual: How End-User Programming Breaks Expertise Barriers",
            "summary": "Abstract This article examines how visual analytics tools can function as end-user programming interfaces that reduce barriers to complex data&hellip;",
            "content_html": "<h2 id=\"abstract\">Abstract</h2>\n<p>This article examines how visual analytics tools can function as end-user programming interfaces that reduce barriers to complex data analysis. Breaking down the research paper “Visual Analytics as End-User Programming” by Sarkar et al. (2015), the article explores how two innovative tools—Teach and Try and Gatherminer—bridge the gap between programming languages and visual outputs, making sophisticated data analysis accessible to non-experts. The researchers demonstrate how visualization itself can become the programming language for analytical procedures.</p><p><strong>Reference:</strong> Sarkar, A., Blackwell, A. F., Jamnik, M., &amp; Spott, M. (2015, January). Visual analytics as end-user programming. Psychology of Programming Interest Group Work-In-Progress Workshop (PPIG-WIP 2015).</p><h2 id=\"traditional-data-analytics-requires-technical-expertise-across-multiple-representations\">Traditional Data Analytics Requires Technical Expertise Across Multiple Representations</h2>\n<p>Data analysis has traditionally been the domain of specialists. The tools of the trade—Excel, R, Python, SQL, Tableau—all involve some form of programming, whether that’s writing formulas, queries, or full-blown code. But there’s an inherent problem with these systems: they create a cognitive burden that excludes many potential users.</p><p>As the researchers note, “there is a disconnect between the programming language and the observable output; the metaphors used for each are discordant.” Imagine trying to analyze customer behavior data. Your data sits in a text file, your analysis happens in Python code, and your results appear as text on a command line. You need to mentally bridge these three different representations to make sense of everything.</p><p>This separation creates what the paper calls a “high expertise barrier to entry.” It’s like trying to cook a complex recipe where the ingredients are in one room, the utensils in another, and the instructions in a third. You’d spend more time running between rooms than actually cooking.</p><p>The paper introduces an alternative: What if the visualization itself could be the programming language?</p><h2 id=\"spreadsheets-can-become-intelligent-learning-interfaces\">Spreadsheets Can Become Intelligent Learning Interfaces</h2>\n<p>The first tool described is “Teach and Try,” which cleverly transforms ordinary spreadsheets into interfaces for building sophisticated statistical models. </p><p>Here’s how it works: You select cells containing data you’re confident about and click “Teach.” These cells become your training data, marked with a green checkmark. Then you select cells where you want predictions and click “Try.” If those cells are empty, they’ll be filled with predictions. If they contain values, they’re color-coded based on how closely they match what the model would predict.</p><p>“Using the familiar metaphor of the spreadsheet, Teach and Try unifies the visual representation of the programming language, the visual representation of the data, and the visual representation of the model output,” the paper explains.</p><p>Consider a teacher grading math exams. After grading several papers, they could “teach” the system the grading pattern (scores of 75+ get an A, 50-74 get a B, 49 and below get a C), then use “Try” to automatically grade the remaining papers. Or they could use it to check another teacher’s grading for consistency.</p><p>The insight here is that the spreadsheet itself becomes both the interface for programming and the display of results. No need to write separate code or interpret command-line outputs. The learning happens right where the data lives.</p><h2 id=\"strategic-visualizations-can-reveal-hidden-patterns-without-programming-expertise\">Strategic Visualizations Can Reveal Hidden Patterns Without Programming Expertise</h2>\n<p>The paper’s second tool, “Gatherminer,” tackles time series data using a visualization technique called a “gatherplot.” </p><p>Traditional time series visualizations often require extensive preprocessing before insights emerge. Gatherplots solve this by applying a strategic layout algorithm that automatically arranges similar time series closer together.</p><p>“The gatherplot is an augmented time series visualisation. It takes the form of a colour-mapped matrix where each row is an individual time series and each column is an individual time point,” the paper describes. This arrangement makes patterns leap out that would otherwise remain hidden.</p><p>But Gatherminer goes beyond visualization. It allows users to select interesting regions in the visualization itself, prompting the system to build a decision tree that explains what distinguishes those regions from others.</p><p>A business analyst examining customer purchase patterns could simply highlight a cluster of unusual activity, and Gatherminer would identify the factors that make those customers different. No SQL queries, no Python code, just direct interaction with the visualization.</p><p>“By bringing the interaction language closer to the visual representations of its output, that is, by attempting to unify ‘how we tell the computer to do it’ with ‘what we want the computer to do’, we hope to reduce the expertise requirements of these analytical procedures,” the researchers write.</p><h2 id=\"visual-programming-democratizes-access-to-advanced-analytics\">Visual Programming Democratizes Access to Advanced Analytics</h2>\n<p>The implications of this approach extend beyond making analysts’ lives easier. These techniques could fundamentally change who can perform sophisticated data analysis.</p><p>“Advanced data analytics is the preserve of a small group of highly-skilled professionals, despite the fact that a much larger population could benefit from access to sophisticated analytics,” the paper points out. By reducing the expertise barrier, these visual programming approaches could democratize access to powerful analytical tools.</p><p>A marketing manager who knows their data but lacks coding skills could use Teach and Try to build a predictive model of customer behavior. A production supervisor could use Gatherminer to identify patterns in manufacturing defects without needing a data scientist’s help.</p><p>This democratization has become increasingly important as data volumes grow and analytics becomes more valuable across all sectors of business and society. When the visualization is the programming language, the focus shifts from coding syntax to domain knowledge and analytical thinking.</p><h2 id=\"the-future-of-analytics-lies-in-bridging-visual-and-computational-thinking\">The Future of Analytics Lies in Bridging Visual and Computational Thinking</h2>\n<p>The ultimate goal described in this research is to unify “how we tell the computer to do it” with “what we want the computer to do.” This unification represents a shift in how we think about programming and data analysis.</p><p>Traditional programming separates the process from the result. Visual analytics as end-user programming merges them, creating a more intuitive and accessible approach.</p><p>As data continues to grow in importance, approaches that lower technical barriers while maintaining analytical power will be essential. By turning visualizations into programming interfaces, we can put powerful analytical tools into the hands of domain experts who understand the problems but lack traditional programming expertise.</p><p>The techniques described in this paper offer a glimpse of that future, where the distinction between visualizing data and analyzing it begins to blur, and where sophisticated analysis becomes accessible to anyone who can recognize a pattern in a visualization.</p><h2 id=\"references\">References</h2>\n<p>Sarkar, A., Blackwell, A. F., Jamnik, M., &amp; Spott, M. (2015, January). Visual analytics as end-user programming. Psychology of Programming Interest Group Work-In-Progress Workshop (PPIG-WIP 2015).</p>",
            "author": {
                "name": "TAP Communications"
            },
            "tags": [
            ],
            "date_published": "2025-04-08T10:20:53+01:00",
            "date_modified": "2025-04-08T10:20:53+01:00"
        },
        {
            "id": "https://advaitsarkar.github.io/autoblog/teach-and-try-machine-learning-for-non-experts-using-spreadsheets.html",
            "url": "https://advaitsarkar.github.io/autoblog/teach-and-try-machine-learning-for-non-experts-using-spreadsheets.html",
            "title": "Teach and Try: Machine Learning for Non-Experts Using Spreadsheets",
            "summary": "Abstract This blog post breaks down the results of the paper “Teach and Try: A simple interaction technique for exploratory&hellip;",
            "content_html": "<h2 id=\"abstract\">Abstract</h2>\n<p>This blog post breaks down the results of the paper “Teach and Try: A simple interaction technique for exploratory data modelling by end users”. The paper presents a novel spreadsheet-based tool that allows users with no statistical training to build and apply sophisticated statistical models. The study demonstrates that this tool can be effectively used by non-experts, and leads them to a better understanding of exploratory data analysis.</p><p><strong>Full Reference:</strong> Sarkar, A., Blackwell, A. F., Jamnik, M., &amp; Spott, M. (2014). Teach and try: A simple interaction technique for exploratory data modelling by end users. In 2014 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC) (pp. 53–56). IEEE. doi:10.1109/VLHCC.2014.6883022.</p><hr>\n<h2 id=\"teach-and-try-empowering-non-experts-with-data-modelling\">Teach and Try: Empowering Non-Experts with Data Modelling</h2>\n<p>In today’s data-driven world, the ability to analyse and interpret data is crucial. However, not everyone has the statistical training required to use advanced data analysis tools. This is where the “Teach and Try” technique comes into play. This tool allows users to perform complex data modelling tasks using a simple spreadsheet interface.</p><p>Traditional data analysis tools, such as programming languages like R and specialised software packages like scikit-learn, require a deep understanding of statistics and programming. This creates a barrier for many users who need to perform data analysis but lack the necessary skills. The “Teach and Try” technique aims to bridge this gap by providing a user-friendly interface that leverages familiar spreadsheet operations.</p><h2 id=\"how-the-teach-and-try-technique-works\">How the Teach and Try Technique Works</h2>\n<p>The “Teach and Try” technique is built on a simple interaction paradigm. Users mark a range of cells in a spreadsheet to indicate their confidence in those values. These marked cells are then used to train a statistical model. Once the training set is specified, users can select another range of cells to apply the model. If the selected cells are empty, the model’s predictions populate them. If the cells already contain values, they are coloured according to their deviation from the model’s predictions.</p><p>The paper explains, “Users mark a range of cells to indicate that they have confidence in those values. The marked cells are used to train a statistical model. Once the training set has been specified in this manner, the user can select any other range of cells, potentially overlapping with the training set, in order to apply the model to those cells”.</p><h2 id=\"a-practical-example-grading-students\">A Practical Example: Grading Students</h2>\n<p>To illustrate the technique, consider a scenario where a maths teacher is grading students based on their exam scores. The teacher marks the scores and corresponding grades for a subset of students. The “Teach and Try” tool uses this data to build a model. The teacher can then apply this model to grade the remaining students. If the grades are missing, the tool fills them in. If the grades are already present, the tool highlights any discrepancies.</p><p>The paper provides a detailed example: “The first column is their score, and the second column is their grade. A score of 75 or above gets an A, 50 to 74 gets B, and 49 or below gets C. Some of the Grade column is pre-populated, and the participants were asked to use the software to ‘quickly grade the remaining students’”.</p><h2 id=\"experimenting-with-the-teach-and-try-technique\">Experimenting with the Teach and Try Technique</h2>\n<p>An experimental study was conducted to evaluate the effectiveness of the “Teach and Try” technique. The study involved 21 participants, including administrative staff from the University of Cambridge Computer Laboratory and BT Research. Most (62%) of the participants “had no prior experience with either machine learning or statistical modelling, but had a basic familiarity with spreadsheet environments.” Each participant completed four statistical tasks using the Teach and Try tool.</p><p>The study found no significant difference in task durations between the experienced and inexperienced participants. Additionally, the second task of any type (filling or evaluation) took less time than the first task, indicating that users quickly learned how to use the tool.</p><h2 id=\"understanding-statistical-concepts\">Understanding Statistical Concepts</h2>\n<p>Participants developed a nontrivial understanding of how the software works. When asked how the computer might be performing the tasks, participants used various explanations, including mathematical terminology, technical constructs, case-based reasoning, and abstract non-technical terms. This demonstrates that users gained a sufficient appreciation of the machine learning paradigm to use the tool confidently.</p><p>The paper notes, “Participants used mathematical terminology to describe their understanding of the software, guessing that it was ‘solving a system of linear equations’, ‘finding some sort of correlation’, or ‘plotting a graph’”. Additionally, some participants explained the software’s behaviour in terms of technology they were familiar with, such as “constructing complicated spreadsheet formulae, SQL queries or conditional formatting rules”.</p><h2 id=\"usability-challenges-and-improvements\">Usability Challenges and Improvements</h2>\n<p>While the “Teach” action was intuitive, some participants initially misunderstood the “Try” action. Common errors included selecting all cells in the target rows or all cells except the target column. Future work might explore alternative labels, such as “Train” and “Test”, to improve usability.</p><p>The paper highlights, “Some participants initially misunderstood how the selection bounds for the ‘Try’ action were being interpreted. The most common error was to select all the cells in the target rows, because they had done exactly that for the ‘Teach’ action”.</p><h2 id=\"related-work-and-distinctions\">Related Work and Distinctions</h2>\n<p>The “Teach and Try” technique shares similarities with other tools, such as WYSIWYT and the Oracle Spreadsheet add-in for Predictive Analytics. However, it distinguishes itself by allowing users without statistical knowledge to build and apply statistical models directly within a spreadsheet interface.</p><p>The paper states, “WYSIWYT allows users without spreadsheet programming knowledge to debug their data, whereas our system allows users without statistical knowledge to build and apply statistical models”.</p><h2 id=\"conclusion-making-data-analysis-accessible\">Conclusion: Making Data Analysis Accessible</h2>\n<p>The “Teach and Try” technique represents a significant step towards making advanced analytical techniques accessible to end-users with no statistical training. By leveraging familiar spreadsheet operations, this tool empowers users to perform complex data modelling tasks and gain a better understanding of exploratory data analysis methods.</p><h2 id=\"references\">References</h2>\n<p>Sarkar, A., Blackwell, A. F., Jamnik, M., &amp; Spott, M. (2014). Teach and try: A simple interaction technique for exploratory data modelling by end users. In 2014 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC) (pp. 53–56). IEEE. doi:10.1109/VLHCC.2014.6883022</p>",
            "image": "https://advaitsarkar.github.io/autoblog/media/posts/12/2025-04-07-teach-try-hero-image.png",
            "author": {
                "name": "TAP Communications"
            },
            "tags": [
            ],
            "date_published": "2025-04-07T17:40:56+01:00",
            "date_modified": "2025-04-08T10:21:33+01:00"
        },
        {
            "id": "https://advaitsarkar.github.io/autoblog/how-hunches-and-sketches-can-help-us-explore-big-data-faster-with-approximate-visualizations.html",
            "url": "https://advaitsarkar.github.io/autoblog/how-hunches-and-sketches-can-help-us-explore-big-data-faster-with-approximate-visualizations.html",
            "title": "How &quot;Hunches and Sketches&quot; Can Help Us Explore Big Data Faster with Approximate Visualizations",
            "summary": "Abstract This article breaks down the findings of the paper “Hunches and Sketches: rapid interactive exploration of large datasets through&hellip;",
            "content_html": "<h2 id=\"abstract\">Abstract</h2>\n<p>This article breaks down the findings of the paper <em>“Hunches and Sketches: rapid interactive exploration of large datasets through approximate visualisations”</em> by Sarkar et al. The paper proposes a practical solution to a modern data science problem: how to visually explore massive datasets quickly and meaningfully on standard hardware. By blending fast approximation algorithms with uncertainty-aware visual techniques, the authors make a compelling case for visual “sketches” that guide human intuition—what they call hunches. This article explains the key ideas, implications, and limitations of their approach for broad audiences.</p><p><strong>Full reference:</strong> Sarkar, A., Blackwell, A. F., Jamnik, M., &amp; Spott, M. (2014). <em>Hunches and Sketches: rapid interactive exploration of large datasets through approximate visualisations</em>. Proceedings of the 8th International Conference on the Theory and Application of Diagrams, Graduate Symposium, 2014 (DIAGRAMS 2014) (pp. 18–22)</p><h2 id=\"visualizing-big-data-often-breaks-our-computers-before-it-enlightens-us\">Visualizing big data often breaks our computers before it enlightens us</h2>\n<p>In the age of big data, the promise is simple: more information should lead to better insights. But there’s a catch. When analysts try to plot millions of data points on a screen, even relatively modern computers buckle under the weight. Scatterplots freeze. Histograms lag. The exploratory momentum evaporates.</p><p>According to the authors, the problem lies not in the vision, but in the execution. “As of this writing it is grindingly slow to render a scatterplot of 10,000,000 points.” They note that although hardware improves over time, data volumes grow faster. Distributed systems offer speedups, but also inflate dataset sizes. This creates an ironic bottleneck. The more data we have, the harder it becomes to visually explore it.</p><p>What’s needed, they argue, is a change in how we think about exploration itself.</p><h2 id=\"sampling-and-sketching-offer-speed-by-sacrificing-precision-and-thats-a-good-thing\">Sampling and sketching offer speed by sacrificing precision, and that’s a good thing</h2>\n<p>The key insight in the paper is that not every analysis requires exact data. Sometimes, a good-enough picture is all an analyst needs to generate ideas. This is where sampling and sketching come in.</p><p>These techniques reduce the data without distorting it. A sample is a small subset that hopefully preserves patterns in the whole. We could also use a compressed data structure, called a “sketch”, that supports approximate queries, like the Bloom filter. Either way, the result is the same: speed.</p><p>These approaches aren’t new. What’s novel here is the focus on visual interaction with approximations. The authors put it bluntly: “data summarisation techniques can be used to interactively render approximate, exploratory visualisations of large datasets.” Instead of showing all the dots, show just enough to see the trend.</p><p>In this view, the goal isn’t to be precise. The goal is to be useful.</p><h2 id=\"approximate-visualizations-support-the-formation-of-hunches-not-formal-conclusions\">Approximate visualizations support the formation of “hunches,” not formal conclusions</h2>\n<p>This leads to the second half of the paper’s argument: approximate visualizations are not just a technical shortcut. They are a cognitive tool. They are a means of sparking what the authors call “hunches”: tentative hypotheses formed through informal visual reasoning.</p><p>Picture a fast-loading histogram with a suspicious-looking dip in the middle. Maybe it’s a sign of a bimodal distribution. Maybe it’s just noise. The point is not to decide yet, but to wonder: “Should I look into this?”</p><p>This kind of open-ended question is central to exploratory data analysis. The paper describes how visualizations support this process: “Visualisations of uncertainty emphasise that these summaries will not support exact inference, but instead facilitate rapid informal reasoning.”</p><p>This is a subtle but important shift. The visualization isn’t there to confirm or reject a hypothesis. It’s there to help make one.</p><h2 id=\"informal-visual-styles-such-as-blur-sketchiness-and-transparency-help-communicate-uncertainty\">Informal visual styles such as blur, sketchiness, and transparency help communicate uncertainty</h2>\n<p>The visuals themselves matter. If an approximation is rendered too cleanly, it might suggest a level of precision that isn’t there. To avoid this, the authors suggest using visual cues that signal uncertainty: transparency, blur, or even a hand-drawn, sketch-like style.</p><p>They cite prior work showing that such styles can actually encourage users to question the visualization. “Sketches are not simply degraded versions of a canonically accurate visual representation,” they note, “but support specific cognitive and social functions.”</p><p>A slightly rough, imprecise look tells the analyst this is a starting point, not the final word. And that mindset is crucial when exploring complex datasets.</p><h2 id=\"approximate-visualizations-may-be-useful-tools-in-the-future-of-exploratory-data-analysis\">Approximate visualizations may be useful tools in the future of exploratory data analysis</h2>\n<p>This paper doesn’t offer a finished product or a polished platform. What it offers is a way of thinking around how we interact with large datasets.</p><p>Instead of being bogged down by the need for complete accuracy at every step, analysts might work with fast, uncertain sketches that help them make better choices about where to look next. The authors argue that this isn’t a compromise, but a strength.</p><p>“The important observation is that a bimodal distribution exists, not the specific frequencies being represented,” they explain. In other words, insight doesn’t always need decimals. Sometimes, a rough shape is enough to light the way.</p><h2 id=\"references\">References</h2>\n<p>Sarkar, A., Blackwell, A. F., Jamnik, M., &amp; Spott, M. (2014). <em>Hunches and Sketches: rapid interactive exploration of large datasets through approximate visualisations</em>. Proceedings of the 8th International Conference on the Theory and Application of Diagrams, Graduate Symposium, 2014 (DIAGRAMS 2014) (pp. 18–22)</p>",
            "image": "https://advaitsarkar.github.io/autoblog/media/posts/11/2025-04-07-hunches-sketches-hero-image.png",
            "author": {
                "name": "TAP Communications"
            },
            "tags": [
            ],
            "date_published": "2025-04-07T15:24:11+01:00",
            "date_modified": "2025-04-07T17:08:18+01:00"
        }
    ]
}
