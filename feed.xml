<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <title>Talking about papers</title>
    <link href="https://advaitsarkar.github.io/autoblog/feed.xml" rel="self" />
    <link href="https://advaitsarkar.github.io/autoblog" />
    <updated>2025-04-07T18:30:27+01:00</updated>
    <author>
        <name>TAP Communications</name>
    </author>
    <id>https://advaitsarkar.github.io/autoblog</id>

    <entry>
        <title>Teach and Try: Machine Learning for Non-Experts Using Spreadsheets</title>
        <author>
            <name>TAP Communications</name>
        </author>
        <link href="https://advaitsarkar.github.io/autoblog/teach-and-try-machine-learning-for-non-experts-using-spreadsheets.html"/>
        <id>https://advaitsarkar.github.io/autoblog/teach-and-try-machine-learning-for-non-experts-using-spreadsheets.html</id>
        <media:content url="https://advaitsarkar.github.io/autoblog/media/posts/12/2025-04-07-teach-try-hero-image.png" medium="image" />

        <updated>2025-04-07T17:40:56+01:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://advaitsarkar.github.io/autoblog/media/posts/12/2025-04-07-teach-try-hero-image.png" alt="" />
                    Abstract This blog post breaks down the results of the paper “Teach and Try: A simple interaction technique for exploratory&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://advaitsarkar.github.io/autoblog/media/posts/12/2025-04-07-teach-try-hero-image.png" class="type:primaryImage" alt="" /></p>
                <h2 id="abstract">Abstract</h2>
<p>This blog post breaks down the results of the paper “Teach and Try: A simple interaction technique for exploratory data modelling by end users”. The paper presents a novel spreadsheet-based tool that allows users with no statistical training to build and apply sophisticated statistical models. The study demonstrates that this tool can be effectively used by non-experts, and leads them to a better understanding of exploratory data analysis.</p><p><strong>Full Reference:</strong> Sarkar, A., Blackwell, A. F., Jamnik, M., &amp; Spott, M. (2014). Teach and try: A simple interaction technique for exploratory data modelling by end users. In 2014 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC) (pp. 53–56). IEEE. doi:10.1109/VLHCC.2014.6883022.</p><hr>
<h2 id="teach-and-try-empowering-non-experts-with-data-modelling">Teach and Try: Empowering Non-Experts with Data Modelling</h2>
<p>In today’s data-driven world, the ability to analyse and interpret data is crucial. However, not everyone has the statistical training required to use advanced data analysis tools. This is where the “Teach and Try” technique comes into play. This tool allows users to perform complex data modelling tasks using a simple spreadsheet interface.</p><p>Traditional data analysis tools, such as programming languages like R and specialised software packages like scikit-learn, require a deep understanding of statistics and programming. This creates a barrier for many users who need to perform data analysis but lack the necessary skills. The “Teach and Try” technique aims to bridge this gap by providing a user-friendly interface that leverages familiar spreadsheet operations.</p><h2 id="how-the-teach-and-try-technique-works">How the Teach and Try Technique Works</h2>
<p>The “Teach and Try” technique is built on a simple interaction paradigm. Users mark a range of cells in a spreadsheet to indicate their confidence in those values. These marked cells are then used to train a statistical model. Once the training set is specified, users can select another range of cells to apply the model. If the selected cells are empty, the model’s predictions populate them. If the cells already contain values, they are coloured according to their deviation from the model’s predictions.</p><p>The paper explains, “Users mark a range of cells to indicate that they have confidence in those values. The marked cells are used to train a statistical model. Once the training set has been specified in this manner, the user can select any other range of cells, potentially overlapping with the training set, in order to apply the model to those cells”.</p><h2 id="a-practical-example-grading-students">A Practical Example: Grading Students</h2>
<p>To illustrate the technique, consider a scenario where a maths teacher is grading students based on their exam scores. The teacher marks the scores and corresponding grades for a subset of students. The “Teach and Try” tool uses this data to build a model. The teacher can then apply this model to grade the remaining students. If the grades are missing, the tool fills them in. If the grades are already present, the tool highlights any discrepancies.</p><p>The paper provides a detailed example: “The first column is their score, and the second column is their grade. A score of 75 or above gets an A, 50 to 74 gets B, and 49 or below gets C. Some of the Grade column is pre-populated, and the participants were asked to use the software to ‘quickly grade the remaining students’”.</p><h2 id="experimenting-with-the-teach-and-try-technique">Experimenting with the Teach and Try Technique</h2>
<p>An experimental study was conducted to evaluate the effectiveness of the “Teach and Try” technique. The study involved 21 participants, including administrative staff from the University of Cambridge Computer Laboratory and BT Research. Most (62%) of the participants “had no prior experience with either machine learning or statistical modelling, but had a basic familiarity with spreadsheet environments.” Each participant completed four statistical tasks using the Teach and Try tool.</p><p>The study found no significant difference in task durations between the experienced and inexperienced participants. Additionally, the second task of any type (filling or evaluation) took less time than the first task, indicating that users quickly learned how to use the tool.</p><h2 id="understanding-statistical-concepts">Understanding Statistical Concepts</h2>
<p>Participants developed a nontrivial understanding of how the software works. When asked how the computer might be performing the tasks, participants used various explanations, including mathematical terminology, technical constructs, case-based reasoning, and abstract non-technical terms. This demonstrates that users gained a sufficient appreciation of the machine learning paradigm to use the tool confidently.</p><p>The paper notes, “Participants used mathematical terminology to describe their understanding of the software, guessing that it was ‘solving a system of linear equations’, ‘finding some sort of correlation’, or ‘plotting a graph’”. Additionally, some participants explained the software’s behaviour in terms of technology they were familiar with, such as “constructing complicated spreadsheet formulae, SQL queries or conditional formatting rules”.</p><h2 id="usability-challenges-and-improvements">Usability Challenges and Improvements</h2>
<p>While the “Teach” action was intuitive, some participants initially misunderstood the “Try” action. Common errors included selecting all cells in the target rows or all cells except the target column. Future work might explore alternative labels, such as “Train” and “Test”, to improve usability.</p><p>The paper highlights, “Some participants initially misunderstood how the selection bounds for the ‘Try’ action were being interpreted. The most common error was to select all the cells in the target rows, because they had done exactly that for the ‘Teach’ action”.</p><h2 id="related-work-and-distinctions">Related Work and Distinctions</h2>
<p>The “Teach and Try” technique shares similarities with other tools, such as WYSIWYT and the Oracle Spreadsheet add-in for Predictive Analytics. However, it distinguishes itself by allowing users without statistical knowledge to build and apply statistical models directly within a spreadsheet interface.</p><p>The paper states, “WYSIWYT allows users without spreadsheet programming knowledge to debug their data, whereas our system allows users without statistical knowledge to build and apply statistical models”.</p><h2 id="conclusion-making-data-analysis-accessible">Conclusion: Making Data Analysis Accessible</h2>
<p>The “Teach and Try” technique represents a significant step towards making advanced analytical techniques accessible to end-users with no statistical training. By leveraging familiar spreadsheet operations, this tool empowers users to perform complex data modelling tasks and gain a better understanding of exploratory data analysis methods.</p><h2 id="references">References</h2>
<p>Sarkar, A., Blackwell, A. F., Jamnik, M., &amp; Spott, M. (2014). Teach and try: A simple interaction technique for exploratory data modelling by end users. In 2014 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC) (pp. 53–56). IEEE. doi:10.1109/VLHCC.2014.6883022</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>How &quot;Hunches and Sketches&quot; Can Help Us Explore Big Data Faster with Approximate Visualizations</title>
        <author>
            <name>TAP Communications</name>
        </author>
        <link href="https://advaitsarkar.github.io/autoblog/how-hunches-and-sketches-can-help-us-explore-big-data-faster-with-approximate-visualizations.html"/>
        <id>https://advaitsarkar.github.io/autoblog/how-hunches-and-sketches-can-help-us-explore-big-data-faster-with-approximate-visualizations.html</id>
        <media:content url="https://advaitsarkar.github.io/autoblog/media/posts/11/2025-04-07-hunches-sketches-hero-image.png" medium="image" />

        <updated>2025-04-07T15:24:11+01:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://advaitsarkar.github.io/autoblog/media/posts/11/2025-04-07-hunches-sketches-hero-image.png" alt="" />
                    Abstract This article breaks down the findings of the paper “Hunches and Sketches: rapid interactive exploration of large datasets through&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://advaitsarkar.github.io/autoblog/media/posts/11/2025-04-07-hunches-sketches-hero-image.png" class="type:primaryImage" alt="" /></p>
                <h2 id="abstract">Abstract</h2>
<p>This article breaks down the findings of the paper <em>“Hunches and Sketches: rapid interactive exploration of large datasets through approximate visualisations”</em> by Sarkar et al. The paper proposes a practical solution to a modern data science problem: how to visually explore massive datasets quickly and meaningfully on standard hardware. By blending fast approximation algorithms with uncertainty-aware visual techniques, the authors make a compelling case for visual “sketches” that guide human intuition—what they call hunches. This article explains the key ideas, implications, and limitations of their approach for broad audiences.</p><p><strong>Full reference:</strong> Sarkar, A., Blackwell, A. F., Jamnik, M., &amp; Spott, M. (2014). <em>Hunches and Sketches: rapid interactive exploration of large datasets through approximate visualisations</em>. Proceedings of the 8th International Conference on the Theory and Application of Diagrams, Graduate Symposium, 2014 (DIAGRAMS 2014) (pp. 18–22)</p><h2 id="visualizing-big-data-often-breaks-our-computers-before-it-enlightens-us">Visualizing big data often breaks our computers before it enlightens us</h2>
<p>In the age of big data, the promise is simple: more information should lead to better insights. But there’s a catch. When analysts try to plot millions of data points on a screen, even relatively modern computers buckle under the weight. Scatterplots freeze. Histograms lag. The exploratory momentum evaporates.</p><p>According to the authors, the problem lies not in the vision, but in the execution. “As of this writing it is grindingly slow to render a scatterplot of 10,000,000 points.” They note that although hardware improves over time, data volumes grow faster. Distributed systems offer speedups, but also inflate dataset sizes. This creates an ironic bottleneck. The more data we have, the harder it becomes to visually explore it.</p><p>What’s needed, they argue, is a change in how we think about exploration itself.</p><h2 id="sampling-and-sketching-offer-speed-by-sacrificing-precision-and-thats-a-good-thing">Sampling and sketching offer speed by sacrificing precision, and that’s a good thing</h2>
<p>The key insight in the paper is that not every analysis requires exact data. Sometimes, a good-enough picture is all an analyst needs to generate ideas. This is where sampling and sketching come in.</p><p>These techniques reduce the data without distorting it. A sample is a small subset that hopefully preserves patterns in the whole. We could also use a compressed data structure, called a “sketch”, that supports approximate queries, like the Bloom filter. Either way, the result is the same: speed.</p><p>These approaches aren’t new. What’s novel here is the focus on visual interaction with approximations. The authors put it bluntly: “data summarisation techniques can be used to interactively render approximate, exploratory visualisations of large datasets.” Instead of showing all the dots, show just enough to see the trend.</p><p>In this view, the goal isn’t to be precise. The goal is to be useful.</p><h2 id="approximate-visualizations-support-the-formation-of-hunches-not-formal-conclusions">Approximate visualizations support the formation of “hunches,” not formal conclusions</h2>
<p>This leads to the second half of the paper’s argument: approximate visualizations are not just a technical shortcut. They are a cognitive tool. They are a means of sparking what the authors call “hunches”: tentative hypotheses formed through informal visual reasoning.</p><p>Picture a fast-loading histogram with a suspicious-looking dip in the middle. Maybe it’s a sign of a bimodal distribution. Maybe it’s just noise. The point is not to decide yet, but to wonder: “Should I look into this?”</p><p>This kind of open-ended question is central to exploratory data analysis. The paper describes how visualizations support this process: “Visualisations of uncertainty emphasise that these summaries will not support exact inference, but instead facilitate rapid informal reasoning.”</p><p>This is a subtle but important shift. The visualization isn’t there to confirm or reject a hypothesis. It’s there to help make one.</p><h2 id="informal-visual-styles-such-as-blur-sketchiness-and-transparency-help-communicate-uncertainty">Informal visual styles such as blur, sketchiness, and transparency help communicate uncertainty</h2>
<p>The visuals themselves matter. If an approximation is rendered too cleanly, it might suggest a level of precision that isn’t there. To avoid this, the authors suggest using visual cues that signal uncertainty: transparency, blur, or even a hand-drawn, sketch-like style.</p><p>They cite prior work showing that such styles can actually encourage users to question the visualization. “Sketches are not simply degraded versions of a canonically accurate visual representation,” they note, “but support specific cognitive and social functions.”</p><p>A slightly rough, imprecise look tells the analyst this is a starting point, not the final word. And that mindset is crucial when exploring complex datasets.</p><h2 id="approximate-visualizations-may-be-useful-tools-in-the-future-of-exploratory-data-analysis">Approximate visualizations may be useful tools in the future of exploratory data analysis</h2>
<p>This paper doesn’t offer a finished product or a polished platform. What it offers is a way of thinking around how we interact with large datasets.</p><p>Instead of being bogged down by the need for complete accuracy at every step, analysts might work with fast, uncertain sketches that help them make better choices about where to look next. The authors argue that this isn’t a compromise, but a strength.</p><p>“The important observation is that a bimodal distribution exists, not the specific frequencies being represented,” they explain. In other words, insight doesn’t always need decimals. Sometimes, a rough shape is enough to light the way.</p><h2 id="references">References</h2>
<p>Sarkar, A., Blackwell, A. F., Jamnik, M., &amp; Spott, M. (2014). <em>Hunches and Sketches: rapid interactive exploration of large datasets through approximate visualisations</em>. Proceedings of the 8th International Conference on the Theory and Application of Diagrams, Graduate Symposium, 2014 (DIAGRAMS 2014) (pp. 18–22)</p>
            ]]>
        </content>
    </entry>
</feed>
