<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <title>Talking about papers</title>
    <link href="https://advaitsarkar.github.io/autoblog/feed.xml" rel="self" />
    <link href="https://advaitsarkar.github.io/autoblog" />
    <updated>2025-04-16T14:59:49+01:00</updated>
    <author>
        <name>TAP Communications</name>
    </author>
    <id>https://advaitsarkar.github.io/autoblog</id>

    <entry>
        <title>Public Acceptance of Self-Driving Cars Reveals a Clear Divide Between Partial and Full Autonomy</title>
        <author>
            <name>TAP Communications</name>
        </author>
        <link href="https://advaitsarkar.github.io/autoblog/public-acceptance-of-self-driving-cars-reveals-a-clear-divide-between-partial-and-full-autonomy.html"/>
        <id>https://advaitsarkar.github.io/autoblog/public-acceptance-of-self-driving-cars-reveals-a-clear-divide-between-partial-and-full-autonomy.html</id>

        <updated>2025-04-16T14:59:49+01:00</updated>
            <summary>
                <![CDATA[
                    Abstract This article examines public perception of autonomous vehicles based on a 2019 research paper that introduced the Autonomous Vehicle&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h2 id="abstract">Abstract</h2>
<p>This article examines public perception of autonomous vehicles based on a 2019 research paper that introduced the Autonomous Vehicle Acceptance Model (AVAM). The study reveals that people perceive only two meaningful levels of autonomy: partial and full, with significantly lower acceptance of fully autonomous vehicles. The findings suggest that automotive manufacturers and technology companies may need different approaches when developing and marketing self-driving cars.</p><p>Reference: Hewitt, C., Politis, I., Amanatidis, T., &amp; Sarkar, A. (2019). Assessing public perception of self-driving cars: The autonomous vehicle acceptance model. In Proceedings of the 24th International Conference on Intelligent User Interfaces (IUI ‘19) (pp. 518–527). ACM. <a href="https://doi.org/10.1145/3301275.3302268">https://doi.org/10.1145/3301275.3302268</a></p><h2 id="the-road-to-autonomous-vehicles-is-paved-with-public-skepticism">The Road to Autonomous Vehicles Is Paved with Public Skepticism</h2>
<p>Imagine stepping into a car with no steering wheel, no pedals, and absolutely no way for you to take control if something goes wrong. How would you feel? According to recent research, probably not great.</p><p>As self-driving cars move from science fiction to reality, understanding public perception becomes crucial for their successful adoption. A study published in 2019 introduced a standardized framework called the Autonomous Vehicle Acceptance Model (AVAM) to measure how people view autonomous vehicles across different levels of automation.</p><p>“Most existing studies of public perception of AVs do not use established models of User Acceptance (UA). They are therefore difficult to make comparisons between or interpret in terms of UA,” the paper notes, highlighting a key gap the research aimed to fill.</p><p>The study examined responses from 187 participants across all six levels of vehicle autonomy defined by the Society of Automotive Engineers (SAE), ranging from Level 0 (fully manual) to Level 5 (fully autonomous with no human intervention required).</p><h2 id="user-acceptance-decreases-as-autonomy-increases">User Acceptance Decreases as Autonomy Increases</h2>
<p>The research findings contradict what might seem intuitive: people actually reported lower expected performance and more difficulty using vehicles as autonomy increased. One might expect that more autonomous vehicles would be perceived as easier to use and more efficient, but the opposite proved true.</p><p>“Not only were participants more anxious about higher levels of autonomy, but they also reported lower expected performance and lower perceived ease-of-use,” the study reports. “This is directly opposed to what we might expect based on the motivating factors in the development of AV.”</p><p>Across nearly all measured factors, including perceived safety, attitude toward the technology, and intention to use the vehicles, participants showed a clear preference for lower levels of autonomy. Anxiety increased significantly with higher autonomy levels, while perceived safety decreased.</p><p>This reluctance isn’t entirely surprising given the novelty of the technology. New innovations often face initial skepticism, especially when they involve removing human control from potentially dangerous situations. The researchers suggest that “more work is needed by experts to clarify the capabilities and limitations of AVs in order to increase trust in the technology.”</p><h2 id="people-see-only-two-real-categories-partial-and-full-automation">People See Only Two Real Categories: Partial and Full Automation</h2>
<p>Perhaps the most intriguing finding was how people conceptualized different levels of autonomy. Despite the industry’s detailed six-level classification system, participants essentially perceived only two categories: partially autonomous (Levels 0-4) and fully autonomous (Level 5).</p><p>This was particularly evident when participants were asked about expected physical engagement with the vehicle. For Levels 0 through 4, participants rated the importance of using hands, feet, and eyes as consistently high, with only minor variations. But for Level 5, there was a dramatic drop in the perceived need for all three forms of engagement.</p><p>“The most likely explanation for this is that users perceive only two levels of autonomy: partial and full, without being able to differentiate well between different levels of partial autonomy,” the paper explains.</p><p>This finding has significant implications for how autonomous vehicles should be designed and marketed. It suggests that incremental improvements in autonomy between Levels 1-4 may not meaningfully change how users interact with or perceive these vehicles.</p><h2 id="the-industry-divide-reflects-public-perception">The Industry Divide Reflects Public Perception</h2>
<p>The study provides an interesting perspective on the current divide in autonomous vehicle development strategies. Some companies, like Tesla and Audi, are introducing autonomous features incrementally, addressing all levels of autonomy. Others, like Waymo and Uber, are aiming directly for Level 5 full autonomy.</p><p>“Technology companies such as Waymo and Uber aiming to directly develop and introduce L5 autonomous vehicles in service of any individual, irrespective of whether they hold a driving licence. In contrast, automotive manufacturers such as Tesla or Audi are aiming to introduce autonomous features incrementally,” the paper notes.</p><p>This industrial split may actually reflect the public’s binary perception of autonomy. If people don’t meaningfully distinguish between different levels of partial autonomy, the incremental approach might not yield the expected benefits in terms of user acceptance and market adoption.</p><h2 id="limitations-of-the-research-should-be-considered">Limitations of the Research Should Be Considered</h2>
<p>Several limitations should be noted when interpreting these results. The study participants were all from the United States and were recruited through Amazon Mechanical Turk, which may have resulted in a more technology-oriented sample than the general population. Additionally, the researchers acknowledge that question order may have introduced some bias, though they defend this choice as helping participants “more easily envision vehicles when the technologies featured became incrementally more hypothetical.”</p><p>The study also primarily sampled current drivers, which might not reflect the views of non-drivers who might benefit most from fully autonomous vehicles. As the researchers note, “It might be interesting to assess the opinions of current non-drivers instead of existing drivers, who constitute the majority of the sample considered.”</p><h2 id="future-research-will-need-to-track-changing-perceptions">Future Research Will Need to Track Changing Perceptions</h2>
<p>Understanding and monitoring public perception will remain crucial as autonomous vehicle technology evolves. The researchers suggest that the AVAM provides a standardized framework that can be used to track changes in perception over time and across different cultures.</p><p>“The AVAM opens up scope for evaluation of many more causal factors of UA [User Acceptance] than are considered here,” the paper states, suggesting future studies could break down results by age, gender, driving experience, and cultural background.</p><p>As autonomous vehicles become more common on roads worldwide, these perceptions will likely shift. The key question remains whether the technology will evolve to meet user expectations, or whether user perceptions will adapt to embrace the new technology.</p><h2 id="references">References</h2>
<p>Hewitt, C., Politis, I., Amanatidis, T., &amp; Sarkar, A. (2019). Assessing public perception of self-driving cars: The autonomous vehicle acceptance model. In Proceedings of the 24th International Conference on Intelligent User Interfaces (IUI ‘19) (pp. 518–527). ACM. <a href="https://doi.org/10.1145/3301275.3302268">https://doi.org/10.1145/3301275.3302268</a></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>When Less Is More: Restricted Language May Improve User Experience in AI Chat Interfaces</title>
        <author>
            <name>TAP Communications</name>
        </author>
        <link href="https://advaitsarkar.github.io/autoblog/when-less-is-more-restricted-language-may-improve-user-experience-in-ai-chat-interfaces.html"/>
        <id>https://advaitsarkar.github.io/autoblog/when-less-is-more-restricted-language-may-improve-user-experience-in-ai-chat-interfaces.html</id>

        <updated>2025-04-16T14:42:29+01:00</updated>
            <summary>
                <![CDATA[
                    Abstract This article breaks down a research study examining whether restricting users to a simplified language interface might actually improve&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h2 id="abstract">Abstract</h2>
<p>This article breaks down a research study examining whether restricting users to a simplified language interface might actually improve their experience compared to allowing unrestricted natural language input. The researchers tested this hypothesis using an interactive language learning game in a 3D blocks world, finding that restricting communication to predefined tokens led to better task performance and improved user experience metrics.</p><p>Reference: Mu, J., &amp; Sarkar, A. (2019). Do we need natural language?: Exploring restricted language interfaces for complex domains. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems (CHI EA ‘19) (pp. LBW2822:1–LBW2822:6). ACM. <a href="https://doi.org/10.1145/3290607.3312975">https://doi.org/10.1145/3290607.3312975</a></p><h2 id="natural-language-interfaces-promise-simplicity-but-often-frustrate-users">Natural language interfaces promise simplicity but often frustrate users</h2>
<p>We’ve all been there. “Alexa, play that song about rivers and roads.” <em>Confused robot noises.</em> “Alexa, play that song… you know… RIVERS AND ROADS?” <em>Alexa plays ‘Old Town Road’</em></p><p>The promise of natural language interfaces (NLIs) - systems where humans can talk to computers using everyday language - seems like the pinnacle of intuitive design. Just tell the computer what you want in your own words! No learning curve! No manuals!</p><p>But the reality often fails to match this promise. Current natural language systems frequently misunderstand users, leading to frustration and disappointment. As the paper notes, “several studies have demonstrated worrying user experience issues with current-generation personal assistants due to mismatches between user expectations and system capabilities.”</p><p>The fundamental problem is that truly understanding human language remains extraordinarily difficult for computers. When an interface suggests you can communicate naturally, it creates expectations that the system may not be able to fulfill.</p><h2 id="the-experiment-used-a-blocks-world-game-to-test-restricted-versus-unrestricted-language">The experiment used a blocks-world game to test restricted versus unrestricted language</h2>
<p>To test whether restricting user language might actually improve experience, the researchers employed an interactive language learning game called SHRDLURN (a nod to the classic SHRDLU system from the 1970s). In this game, users need to manipulate colored blocks from a starting configuration to a goal configuration by issuing text commands to the computer.</p><p>The game was intentionally designed so users would need to develop a communication system with the computer from scratch. The computer uses a learning algorithm to interpret commands, improving its understanding as more commands are issued.</p><p>Participants were split into two groups:</p><ul>
<li>An unrestricted group who could type any commands they wanted</li>
<li>A restricted group who could only use 11 specific tokens matching the system’s internal logical primitives (all, cyan, red, brown, orange, except, leftmost, rightmost, add, remove, to)</li>
</ul>
<p>What makes this setup fascinating is that it mirrors many real-world interactions with digital assistants, where the underlying capability of the system is hidden, and users must build a mental model of what the system can understand.</p><h2 id="restricted-language-led-to-better-performance-and-reduced-mental-effort">Restricted language led to better performance and reduced mental effort</h2>
<p>Counter to what many would expect, constraining users to a limited vocabulary resulted in the same or better task performance. Restricted participants needed an average of 7.63 scrolls per utterance, compared to unrestricted users’ 12.9 scrolls (scrolling was necessary when the computer misunderstood the command). Though the difference wasn’t statistically significant (p = 0.13), the trend favored the restricted condition.</p><p>More striking were the differences in user experience. On NASA Task Load Index (NASA-TLX) measurements, restricted users reported:</p><ul>
<li>Significantly less required effort (48.8 vs 72.5, p = 0.014)</li>
<li>Significantly higher perceived performance (66.9 vs 39.4, p = 0.005)</li>
<li>Lower mental demand (54.4 vs 75.6, p = 0.06, marginally significant)</li>
</ul>
<p>Frustration levels were similar between groups, suggesting that the restrictions didn’t annoy users as one might expect.</p><h2 id="users-naturally-gravitating-to-simpler-language-performed-better">Users naturally gravitating to simpler language performed better</h2>
<p>Perhaps the most telling finding came from analyzing the communication strategies of participants in the unrestricted condition. The most successful unrestricted users independently developed simple, consistent languages resembling the restricted condition.</p><p>The paper provides examples contrasting successful and unsuccessful users:</p><pre><code>Player 1/8 (Mean scrolls/utterance: 4.08)
add blue blocks to blue blocks
add red block on the last orange stack
remove last red block
remove top orange blocks
remove first red block

Player 8/8 (Mean scrolls/utterance: 28.9)
move nothing
move all but blue
move all but red
remove 5th
remove first
</code></pre>
<p>The high-performing player used a consistent pattern of commands, while the struggling player employed inconsistent terminology and structure. This suggests that even when given free rein, users who naturally adopt simpler, more structured communication fare better.</p><h2 id="the-implications-extend-to-real-world-interface-design">The implications extend to real-world interface design</h2>
<p>The results suggest an interesting middle ground for interface design. Rather than choosing between fully natural language (which is hard to build and creates unrealistic expectations) or traditional interfaces (which require learning curves), a “restricted language interface” might offer the best of both worlds.</p><p>“More generally, rather than considering only two extremes—a specialized programming language or GUI versus a human-level language understanding system—designers should consider ‘restricted’ language interfaces which trade off full expressivity for simplicity, learnability, and consistency,” the paper argues.</p><p>This approach could be particularly valuable for domains with well-defined action spaces, like data analysis, database querying, or robot control. By guiding users toward consistent language patterns that match what the system can understand, designers might create interfaces that not only perform better but also feel better to use.</p><h2 id="the-limitations-suggest-caution-when-generalizing-these-findings">The limitations suggest caution when generalizing these findings</h2>
<p>The study comes with important caveats. The findings apply primarily to text-based interfaces rather than voice, since text input “is more amenable to restriction and shorthand than voice communication.” The results may also be limited to well-specified domains with finite action spaces, unlike open-ended tasks such as general conversation or answering arbitrary questions.</p><p>The sample size was relatively small (16 participants), and the experimental task was quite specific. Additionally, the blocks world represents a simplified environment compared to many real-world applications.</p><p>Nevertheless, the study offers a fascinating counterpoint to the assumption that more freedom in language interfaces always leads to better experiences. Sometimes, a little structure goes a long way.</p><p>For designers of conversational interfaces, the message is clear: don’t try to boil the ocean by supporting every possible way a human might express a command. Instead, consider how to subtly guide users toward language patterns the system can reliably interpret. This guidance might not only make the system easier to build, but also more satisfying to use.</p><h2 id="references">References</h2>
<p>Mu, J., &amp; Sarkar, A. (2019). Do we need natural language?: Exploring restricted language interfaces for complex domains. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems (CHI EA ‘19) (pp. LBW2822:1–LBW2822:6). ACM. <a href="https://doi.org/10.1145/3290607.3312975">https://doi.org/10.1145/3290607.3312975</a></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Chatbots as Therapists: Why the Human Touch Still Matters in Mental Health Care</title>
        <author>
            <name>TAP Communications</name>
        </author>
        <link href="https://advaitsarkar.github.io/autoblog/chatbots-as-therapists-why-the-human-touch-still-matters-in-mental-health-care.html"/>
        <id>https://advaitsarkar.github.io/autoblog/chatbots-as-therapists-why-the-human-touch-still-matters-in-mental-health-care.html</id>

        <updated>2025-04-16T14:33:22+01:00</updated>
            <summary>
                <![CDATA[
                    Abstract This article breaks down the results of a comparative study examining how people perceive therapy sessions with chatbots versus&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h2 id="abstract">Abstract</h2>
<p>This article breaks down the results of a comparative study examining how people perceive therapy sessions with chatbots versus human therapists. The research found that participants rated chatbot therapy sessions as less enjoyable and less smooth than sessions with human therapists, highlighting significant challenges for AI-based mental health interventions. The study suggests important limitations and future directions for research into automated therapeutic approaches. </p><p>Reference: Bell, S., Wood, C., &amp; Sarkar, A. (2019). Perceptions of chatbots in therapy. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems (CHI EA ‘19) (pp. LBW1712:1–LBW1712:6). ACM. <a href="https://doi.org/10.1145/3290607.3313072">https://doi.org/10.1145/3290607.3313072</a></p><h2 id="the-mental-health-accessibility-gap-is-driving-innovation-in-digital-therapy">The mental health accessibility gap is driving innovation in digital therapy</h2>
<p>Mental illness affects approximately one-third of the global population during their lifetime, creating an enormous health burden. While effective treatments like Cognitive Behavioral Therapy (CBT) exist, many people struggle to access care due to long wait lists, high costs, and logistical barriers such as transportation and scheduling challenges.</p><p>This accessibility gap has spurred interest in technology-based solutions. Internet-based CBT has shown promising clinical results by eliminating the need for face-to-face sessions. However, a significant bottleneck remains: the limited number of qualified therapists available to provide treatment.</p><p>Enter the chatbot therapist, an AI-powered solution that could potentially scale therapy access dramatically. But a key question remains unanswered: How do people actually experience therapy when it’s delivered by a chatbot instead of a human?</p><h2 id="university-researchers-conducted-a-controlled-experiment-comparing-human-and-ai-therapy">University researchers conducted a controlled experiment comparing human and AI therapy</h2>
<p>To investigate this question, researchers designed a comparative study with 10 participants who self-identified as experiencing subclinical symptoms of stress. These participants were divided into two groups of five people each.</p><p>Group A received two 30-minute sessions of internet-based CBT from a human therapist through a chat interface. Group B believed they were receiving therapy from a chatbot through the same interface, though in reality, the “chatbot” was simulated using a technique called Wizard of Oz, where human operators selected appropriate responses from a predetermined script.</p><p>After each session, participants completed questionnaires measuring their perceptions of the therapy across multiple dimensions, including sharing ease (how comfortable they felt sharing personal information), conversation smoothness, usefulness, and enjoyment. The researchers also conducted qualitative interviews to gather additional insights.</p><h2 id="chatbot-therapy-conversations-were-significantly-less-smooth-than-human-interactions">Chatbot therapy conversations were significantly less smooth than human interactions</h2>
<p>One of the clearest findings from the study concerned conversation flow. Participants who believed they were talking to a chatbot rated their conversations as significantly less smooth than those speaking with human therapists. Group A (human therapist) reported a mean smoothness score of 6.1 out of 7, while Group B (chatbot) scored only 5.0 - a statistically significant difference.</p><p>This lack of conversational flow was frequently mentioned in participant interviews. One participant noted that the chatbot’s responses felt like “repetition of what I said, not an expansion of what I said.” Another complained that the responses seemed generic: “I felt standard answers come back… anybody could say that.”</p><p>The perceived rigidity of chatbot communication appears to be a major drawback, with 60% of participants in the chatbot group spontaneously commenting on the difficulties of chat-based therapy. As one participant put it: “Text is not always as nice as sitting down to something face-to-face, especially with body language.”</p><h2 id="therapy-sessions-with-chatbots-were-perceived-as-less-enjoyable-than-with-humans">Therapy sessions with chatbots were perceived as less enjoyable than with humans</h2>
<p>Another significant finding concerned enjoyment. Participants in the chatbot group reported lower enjoyment levels than those in the human therapist group, a difference that reached statistical significance. When asked to rate their sessions on a scale from “Bad” to “Good,” the human therapist group gave a median rating of 6.0, while the chatbot group gave only 5.0.</p><p>The qualitative interviews shed light on why chatbot sessions might be less enjoyable. Many participants commented on the superficial nature of the chatbot’s responses and its inability to provide detailed or personalized guidance. One participant said the chatbot “suggested keeping a thought journal, but then it didn’t really expand on what it meant.”</p><h2 id="the-empathy-gap-presents-a-fundamental-challenge-for-automated-therapy">The empathy gap presents a fundamental challenge for automated therapy</h2>
<p>Perhaps the most fundamental issue identified in the study was the difficulty chatbots have in conveying empathy and building therapeutic relationships. One participant articulated this challenge clearly:</p><p>“When you tell something to someone, it’s better, because they might have gone through something similar… there’s no sense that the robot cares or understands or empathizes.”</p><p>This highlights a core element of effective therapy: the therapeutic alliance between patient and provider. This relationship is built on trust, empathy, and shared understanding, qualities that current chatbot technology struggles to replicate.</p><p>The study suggests that future research should focus specifically on addressing these limitations. Without developing ways for chatbots to demonstrate empathy, maintain conversational context, and build meaningful relationships with users, fully automated therapy may remain significantly less effective than human-delivered care.</p><h2 id="small-sample-size-limits-the-generalizability-of-these-findings">Small sample size limits the generalizability of these findings</h2>
<p>While this study provides valuable insights, several limitations should be considered when interpreting the results. The most obvious is the small sample size of just 10 participants, which limits statistical power and generalizability. Additionally, participants only engaged in two 30-minute sessions, which doesn’t reflect the longer-term nature of most therapeutic relationships.</p><p>The Wizard of Oz technique used to simulate the chatbot may not perfectly represent the capabilities of actual therapeutic chatbots. The researchers note that “no suitably advanced therapy chatbot exists today,” underscoring the emerging nature of this technology.</p><h2 id="the-future-of-therapy-may-involve-human-ai-collaboration-rather-than-replacement">The future of therapy may involve human-AI collaboration rather than replacement</h2>
<p>Despite these challenges, the potential benefits of chatbot-assisted therapy remain significant. Increased accessibility, lower costs, and 24/7 availability could help address the enormous unmet need for mental health services globally.</p><p>Rather than viewing chatbots as replacements for human therapists, a more promising approach might be combining humans and AI in a therapeutic system. Chatbots could handle initial screening, routine check-ins, and homework assistance, while human therapists focus on building relationships and addressing complex issues.</p><p>The study concludes with a call for research that acknowledges and directly addresses the current limitations of chatbot therapy: “We suggest that future research into chatbot CBT acknowledges and explores these areas of conversational recall, empathy, and the challenge of shared experience, in the hope that we may benefit from scalable, accessible therapy where needed.”</p><p>As technology continues to advance, the gap between human and chatbot therapy may narrow. But this research suggests that for now, the human touch remains an essential component of effective mental health care.</p><h2 id="references">References</h2>
<p>Bell, S., Wood, C., &amp; Sarkar, A. (2019). Perceptions of chatbots in therapy. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems (CHI EA ‘19) (pp. LBW1712:1–LBW1712:6). ACM. <a href="https://doi.org/10.1145/3290607.3313072">https://doi.org/10.1145/3290607.3313072</a></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Understanding the User Experience of Probabilistic Programming Languages</title>
        <author>
            <name>TAP Communications</name>
        </author>
        <link href="https://advaitsarkar.github.io/autoblog/understanding-the-user-experience-of-probabilistic-programming-languages.html"/>
        <id>https://advaitsarkar.github.io/autoblog/understanding-the-user-experience-of-probabilistic-programming-languages.html</id>

        <updated>2025-04-16T14:22:36+01:00</updated>
            <summary>
                <![CDATA[
                    Abstract This article breaks down a discussion paper that explores the usability challenges of probabilistic programming languages (PPLs) and proposes&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h2 id="abstract">Abstract</h2>
<p>This article breaks down a discussion paper that explores the usability challenges of probabilistic programming languages (PPLs) and proposes ways to make these powerful tools more accessible to non-specialists. The paper brings together perspectives from psychology of programming, educational approaches, and end-user development to address how PPLs might reach broader audiences.</p><p>Reference: Blackwell, A., Church, L., Erwig, M., Geddes, J., Gordon, A., Gorinova, M., Gunes Baydin, A., Gram-Hansen, B., Kohn, T., Lawrence, N., Mansinghka, V., Paige, B., Petricek, T., Robinson, D., Sarkar, A., &amp; Strickson, O. (2019). Usability of probabilistic programming languages. In Proceedings of the 30th Annual Conference of the Psychology of Programming Interest Group (PPIG 2019).</p><h2 id="what-makes-programming-with-uncertainty-so-challenging-for-humans">What Makes Programming with Uncertainty So Challenging for Humans</h2>
<p>The world runs on probability, not certainty. From weather forecasts to medical diagnoses, we constantly navigate through uncertainties. Yet the tools designed to handle these probabilities remain largely inaccessible to anyone without specialized training.</p><p>Probabilistic programming languages (PPLs) represent a powerful paradigm for modeling uncertainty and making data-driven inferences. Unlike conventional programming where variables have fixed values, PPLs treat variables as probability distributions. This fundamental shift creates unique usability challenges for programmers and potential users.</p><p>“A key distinction in relation to conventional programming languages is that variables do not have a single value, but should be regarded as defining (or sampling from) a probability distribution of likely values,” the paper explains. This concept alone represents a significant mental hurdle for many learners.</p><p>Consider how we typically learn to program: variables hold specific values that change in predictable ways. PPLs flip this understanding on its head, asking programmers to think in terms of distributions and possibilities rather than deterministic outcomes.</p><h2 id="the-gap-between-statisticians-and-everyday-users-continues-to-widen">The Gap Between Statisticians and Everyday Users Continues to Widen</h2>
<p>While artificial intelligence and data science have entered mainstream consciousness, the tools needed to work with probabilistic models remain largely restricted to specialists. The paper highlights this gap by drawing a parallel with spreadsheets, noting that “more people create programs in spreadsheets such as Excel than in all other programming languages combined.”</p><p>This comparison is telling. Spreadsheets succeeded because they offer a concrete perspective on the user’s data rather than focusing on programming abstractions. Could a similar approach work for probabilistic programming?</p><p>The answer might lie in creating interfaces that bridge the conceptual gap between everyday understanding and the mathematical formalism of probability theory. For instance, visualizing probability distributions could help users grasp these abstract concepts without requiring deep statistical knowledge.</p><h2 id="visual-metaphors-could-transform-how-we-understand-probability">Visual Metaphors Could Transform How We Understand Probability</h2>
<p>One promising approach detailed in the paper involves using spatial partitions as a visual metaphor for understanding probabilistic values. Instead of writing complex mathematical notation, users could interact with visual blocks representing probability distributions.</p><p>“Spatial partitions can serve as a simple visual metaphor for illustrating discrete probabilistic values,” the authors propose, describing a system where the area occupied by each value corresponds to its probability. This approach makes tangible what is otherwise highly abstract.</p><p>Imagine seeing a fair coin toss represented as two equal rectangles labeled “Heads” and “Tails,” each occupying 50% of the space. Now imagine combining this with another random event, like drawing a colored ball from an urn. The visual representation would show how these probabilities interact, making complex concepts like conditional probability more intuitive.</p><p>Such visualizations could transform how probability is taught in schools and how probabilistic models are created in practical applications. They provide an entry point for those who might otherwise be intimidated by the mathematical formalism.</p><h2 id="end-user-development-could-democratize-data-science-skills">End-User Development Could Democratize Data Science Skills</h2>
<p>The paper makes a compelling case for considering PPLs from an end-user development perspective. End-user developers are people who create programs to solve practical problems rather than out of technical interest or as professional programmers.</p><p>“Increased business interest in the methods of statistical data science suggests that these end-users are likely to find value in PPL capabilities,” the paper states, especially if these capabilities are presented in familiar contexts like spreadsheets.</p><p>This approach could change how people interact with data. Rather than treating data wrangling, modeling, and analysis as separate steps, an integrated approach could allow users to explore data and build models simultaneously, gaining insights through iterative experimentation.</p><p>The authors describe a project called “nocell” where “the result of running a program written in this language is a spreadsheet model applied to the input data.” This bridges sophisticated probabilistic modeling with the familiarity of spreadsheets, potentially opening the door for many more people to engage with data science.</p><h2 id="educational-approaches-should-consider-diverse-learning-needs">Educational Approaches Should Consider Diverse Learning Needs</h2>
<p>The paper also considers how PPLs might be used in education, drawing inspiration from languages like Scratch that have successfully introduced programming concepts to children.</p><p>“Much traditional teaching of probability follows the traditions of Bayes himself, and other early theorists, in exploring the mathematical implications of gambling (coin tosses, dice throws etc),” the authors note. But contemporary problems in data science might prove more motivating for today’s learners.</p><p>Imagine students using probabilistic programming to analyze traffic data near their school, or to explore patterns in social media. These real-world applications could make abstract concepts tangible and relevant, fostering deeper understanding.</p><p>The authors suggest that visual representations of models could be particularly valuable for learning. Studies show that when users can see visualizations of Bayesian networks alongside code, they develop higher-level understanding of model dependencies rather than focusing solely on implementation details.</p><h2 id="limitations-and-future-directions-for-ppl-research">Limitations and Future Directions for PPL Research</h2>
<p>While the paper presents promising approaches to making PPLs more usable, several limitations should be noted. The visualizations described are primarily focused on discrete probability distributions and may not scale well to more complex models. Additionally, the educational benefits of these approaches remain theoretical until more extensive classroom studies are conducted.</p><p>The paper represents a starting point for discussion rather than presenting definitive solutions. “This paper should primarily be regarded as a manifesto for promising research directions in the development of more usable PPLs,” the authors explicitly state.</p><p>Future research will need to address how these approaches scale to real-world problems, how different user groups interact with probabilistic concepts, and what specific design patterns prove most effective for various applications.</p><h2 id="references">References</h2>
<p>Blackwell, A., Church, L., Erwig, M., Geddes, J., Gordon, A., Gorinova, M., Gunes Baydin, A., Gram-Hansen, B., Kohn, T., Lawrence, N., Mansinghka, V., Paige, B., Petricek, T., Robinson, D., Sarkar, A., &amp; Strickson, O. (2019). Usability of probabilistic programming languages. In Proceedings of the 30th Annual Conference of the Psychology of Programming Interest Group (PPIG 2019).</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Bringing Probabilities to the People: How Spreadsheets Could Learn to Think in Uncertainty</title>
        <author>
            <name>TAP Communications</name>
        </author>
        <link href="https://advaitsarkar.github.io/autoblog/bringing-probabilities-to-the-people-how-spreadsheets-could-learn-to-think-in-uncertainty.html"/>
        <id>https://advaitsarkar.github.io/autoblog/bringing-probabilities-to-the-people-how-spreadsheets-could-learn-to-think-in-uncertainty.html</id>

        <updated>2025-04-16T14:02:31+01:00</updated>
            <summary>
                <![CDATA[
                    Abstract This article breaks down the key findings of the paper End-User Probabilistic Programming, which explores how millions of everyday&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h2 id="abstract">Abstract</h2>
<p>This article breaks down the key findings of the paper <em>End-User Probabilistic Programming</em>, which explores how millions of everyday spreadsheet users navigate uncertainty, and whether probabilistic programming, normally reserved for experts, could be brought into their domain. It explains the study’s qualitative research into spreadsheet user behaviors and presents the proposed technical enhancements to make probabilistic modeling more intuitive and accessible.  </p><p>Reference: Borghouts, J., Gordon, A. D., Sarkar, A., &amp; Toronto, N. (2019). End-user probabilistic programming. In Quantitative evaluation of systems (pp. 3–24). Springer International Publishing. <a href="https://doi.org/10.1007/978-3-030-30281-8_1">https://doi.org/10.1007/978-3-030-30281-8_1</a></p><h2 id="probabilistic-thinking-is-hard-probabilistic-coding-is-harder">Probabilistic thinking is hard. Probabilistic coding is harder.</h2>
<p>It’s one thing to say, “We might not make budget this month.”<br>It’s another to code that uncertainty into a model that can tell you, mathematically, what “might” really means.</p><p>Probabilistic programming is a way to model uncertainty by writing code that says, in essence: “This part’s a guess. This part’s a guess too. Tell me what happens.” Traditionally, it lives in the realm of expert statisticians and data scientists, working with tools like Stan or BUGS.</p><p>But tens or hundreds of millions of people already do informal modeling under uncertainty. They use Excel. They make budgets, forecasts, and plans that mix hard data with educated guesses. They do this without thinking of themselves as programmers or probabilists. This paper asks: What if spreadsheets learned to speak uncertainty in a more formal, helpful way?</p><h2 id="spreadsheet-users-deal-with-uncertainty-constantly-but-informally">Spreadsheet users deal with uncertainty constantly, but informally.</h2>
<p>Interviews with 11 spreadsheet users revealed six recurring types of uncertainty in their everyday work: estimates, dynamic data, errors, missing data, unfindable data, and untraceable data.</p><p>By far the most common? Estimates. As one participant put it, “All we can do is make best estimates.”</p><p>Users cope through a wide range of strategies: from acquiring more data, to adding comments, to simply ignoring the problem. Some highlight cells. Others explain the fuzziness verbally in reports. A few run multiple scenarios manually, copying the sheet over and over to simulate “what if” cases. </p><p>The ingenuity is impressive. The lack of structured support is striking.</p><h2 id="formal-tools-for-uncertainty-in-spreadsheets-exist-but-are-barely-used">Formal tools for uncertainty in spreadsheets exist, but are barely used.</h2>
<p>Many spreadsheets today include basic probabilistic tools like the <code>RAND()</code> function or Monte Carlo simulations. Add-ins like @Risk or Crystal Ball allow more sophisticated modeling. Yet usage is niche.</p><p>One key reason: they require users to simulate not just the data, but the underlying statistical inference. That is, users must manually replicate the logic of uncertainty.</p><p>In contrast, probabilistic programming lets users define a model, such as “Income is fixed; expenses vary”, and lets the system figure out the math. This automation is powerful. But traditional probabilistic programming languages are intimidating. The average spreadsheet user isn’t likely to download Stan to model their electric bill.</p><p>The paper proposes a middle ground: bringing probabilistic programming principles <em>into</em> the spreadsheet environment itself.</p><h2 id="proposed-upgrades-let-cells-hold-uncertainty-and-propagate-it-through-formulas">Proposed upgrades: Let cells hold uncertainty and propagate it through formulas.</h2>
<p>The authors explore three kinds of “uncertain values” a cell might hold:</p><ul>
<li><p><strong>Qualitative uncertainty</strong>: A value tagged as approximate. For example, <code>ESTIMATE(100)</code> indicates a rough guess. This label can propagate through calculations, so the final balance might show as <code>ESTIMATE(15)</code>.</p></li>
<li><p><strong>Possibilistic uncertainty</strong>: A set of discrete scenarios. For instance, <code>SCENARIOS(50, 100, 150)</code> might represent best, expected, and worst-case costs for utilities. The formulas downstream return sets too, like <code>SCENARIOS(65, 15, -35)</code> for a budget balance.</p></li>
<li><p><strong>Probabilistic uncertainty</strong>: A full probability distribution, like <code>DIST.TRIANG(50, 150, 100)</code>, indicating a most likely value with a known spread. This allows calculations like, “What’s the chance I go into overdraft?” with a result like “25%.”</p></li>
</ul>
<p>Each level increases in sophistication and demands more from the user.</p><h2 id="more-robust-modeling-could-be-enabled-by-sheet-defined-functions">More robust modeling could be enabled by “sheet-defined functions.”</h2>
<p>One elegant solution for complexity is to encapsulate reusable logic inside what the authors call “sheet-defined functions.” These are like mini-programs defined within a sheet, which take parameters and return outputs. Clara, a fictional user modeling her sofa budget, could define her budget as a function that takes one input - her utilities bill, and returns whether she goes over.</p><p>With this function, she could feed in many different inputs, either scenarios or random samples, and collect outputs without rewriting formulas for each case. It’s clean, scalable, and more reliable than the copy-and-paste chaos of typical Monte Carlo simulations.</p><h2 id="probabilistic-programming-wont-fix-every-type-of-uncertainty">Probabilistic programming won’t fix every type of uncertainty.</h2>
<p>Despite the technical elegance of uncertain values and sheet-defined functions, the authors emphasize that these tools can’t solve everything.</p><p>Two categories of uncertainty, <em>unfindable data</em> and <em>untraceable data</em>, stem not from randomness, but from limitations in how data is structured or tracked. As one user noted, they couldn’t extract weekend hours from a timesheet, not because the data was missing, but because they didn’t know how to write the formula.</p><p>Probabilistic models can’t help much when users can’t access or understand their own data. For that, better tools for formula authoring, layout guidance, and data provenance would be needed.</p><h2 id="users-want-support-for-uncertainty-but-not-everyone-wants-probability">Users want support for uncertainty, but not everyone wants probability.</h2>
<p>Interestingly, while probabilistic tools are powerful, they are not always the right fit. Possibilistic models like scenario analysis are already widely used and well understood. Qualitative tags are simple but broadly useful. Probabilistic models are precise, but often intimidating for non-experts.</p><p>The authors conclude: “No single formalism emerges the clear winner.” In fact, probabilistic representations may not be worth implementing on their own unless paired with clearer input interfaces, visualization tools, and guidance for interpreting outputs.</p><h2 id="a-cautious-optimism-for-the-probabilistic-spreadsheet-future">A cautious optimism for the probabilistic spreadsheet future.</h2>
<p>Spreadsheets have always been a platform for democratizing computation. From the first <code>SUM()</code> to today’s pivot tables, they offer power without programming.</p><p>End-user probabilistic programming could be the next evolution but only if it’s introduced carefully. Simplicity matters. Interpretability matters. Visual feedback matters.</p><p>Above all, flexibility matters. As one participant explained, “We dont know exactly what’s going to happen. All we can do is make best estimates.”</p><h2 id="references">References</h2>
<p>Borghouts, J., Gordon, A. D., Sarkar, A., &amp; Toronto, N. (2019). End-user probabilistic programming. In Quantitative evaluation of systems (pp. 3–24). Springer International Publishing. <a href="https://doi.org/10.1007/978-3-030-30281-8_1">https://doi.org/10.1007/978-3-030-30281-8_1</a></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>When Complexity Becomes Relative: Improving Word Complexity Identification Through Comparative Judgments</title>
        <author>
            <name>TAP Communications</name>
        </author>
        <link href="https://advaitsarkar.github.io/autoblog/when-complexity-becomes-relative-improving-word-complexity-identification-through-comparative-judgments.html"/>
        <id>https://advaitsarkar.github.io/autoblog/when-complexity-becomes-relative-improving-word-complexity-identification-through-comparative-judgments.html</id>

        <updated>2025-04-16T13:53:59+01:00</updated>
            <summary>
                <![CDATA[
                    Abstract This article breaks down the results of a research paper investigating whether comparative judgments lead to more reliable annotations&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h2 id="abstract">Abstract</h2>
<p>This article breaks down the results of a research paper investigating whether comparative judgments lead to more reliable annotations than binary classifications when identifying complex words in text. The study demonstrates that having annotators rank words by complexity rather than simply labeling them as “complex” or “not complex” yields higher agreement and potentially more efficient data collection.</p><p>Reference: Gooding, S., Kochmar, E., Sarkar, A., &amp; Blackwell, A. (2019). Comparative judgments are more consistent than binary classification for labelling word complexity. In Proceedings of the 13th Linguistic Annotation Workshop (pp. 208–214). Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/W19-4024">https://doi.org/10.18653/v1/W19-4024</a></p><h2 id="identifying-complex-words-helps-create-more-accessible-text">Identifying complex words helps create more accessible text</h2>
<p>Imagine you’re reading a dense academic paper or a legal document. You encounter words like “ameliorate,” “politicizing,” or “substantively.” For many readers, especially those learning English or with reading difficulties, these words create barriers to understanding.</p><p>This is where lexical simplification comes in. It’s the process of replacing difficult words with simpler alternatives while preserving meaning. For example, changing “ameliorate” to “improve” or “substantively” to “significantly.” But before computers can help simplify text automatically, they need to learn which words actually need simplification in context.</p><p>The first crucial step in this process is called Complex Word Identification (CWI). It’s the foundation of any good text simplification system.</p><p>“Lexical simplification can be framed as a two step procedure, where the algorithm needs to first identify which words (or more specifically word senses) in context require simplification, and then replace them with simpler alternatives,” explains the paper. “The first step is commonly referred to as complex word identification.”</p><p>But teaching computers to recognize complex words isn’t straightforward. Humans need to provide examples by labeling words in text as either complex or not complex. These labeled examples then train machine learning models to make predictions about new words. However, previous attempts at creating such datasets have suffered from a significant problem: people often disagree about what makes a word complex.</p><h2 id="previous-complex-word-identification-efforts-have-shown-poor-annotator-agreement">Previous complex word identification efforts have shown poor annotator agreement</h2>
<p>When multiple people label the same data, researchers want to see high “inter-annotator agreement” – a measure of how consistently different people apply the same labels. Previous complex word identification datasets have shown remarkably low agreement.</p><p>In one dataset from 2012, the agreement score (measured using Cohen’s Kappa) was just 0.398. Another from 2016 had an even lower score (Krippendorff’s Alpha) of 0.244. A third dataset from 2018 found that only 1.1% of words were unanimously marked as complex by all 20 annotators. According to standard interpretations of these metrics, these scores represent “minimal agreement” or “inconclusive” results.</p><p>Why so much disagreement? Word complexity is inherently subjective. What seems complex depends on your vocabulary, education, native language, age, and many other factors. Previous annotation efforts did not control for these variables.</p><p>“The homogeneity of the annotator group is usually not controlled for, meaning that labels are provided by individuals with various backgrounds, conflating factors such as age, native language and education,” notes the paper.</p><p>Additionally, these studies forced annotators to make binary decisions about word complexity, but complexity exists on a spectrum. A word isn’t simply “complex” or “not complex” – it can be “somewhat complex” or “very complex” relative to other words.</p><h2 id="comparative-judgments-produce-more-consistent-annotations-than-binary-classifications">Comparative judgments produce more consistent annotations than binary classifications</h2>
<p>The researchers set out to test whether a different approach could yield better results. They recruited 30 annotators who shared similar backgrounds: all were native English speakers, had graduate degrees, and were between 21-30 years old. Each person completed two different annotation tasks using words selected from previous datasets.</p><p>In the first task, annotators used a traditional binary approach – clicking on words they considered complex. In the second task, they ranked words according to their relative complexity. The results were clear: comparative judgments produced significantly higher agreement.</p><p>“Using the Kappa interpretations, the comparative (ranking) labelling task has a moderate level of agreement, whereas the agreement in the binary annotation task is minimal, showing that the comparative judgment leads to a higher level of agreement than the binary categorisation judgment,” reports the paper.</p><p>The agreement scores for the ranking task reached 0.6775 (Kappa) and 0.6821 (Alpha) – well above the threshold considered reliable for drawing conclusions. By comparison, the binary task scores were much lower: 0.3937 (Kappa) and 0.4960 (Alpha).</p><h2 id="ranking-words-by-complexity-is-faster-than-binary-classification">Ranking words by complexity is faster than binary classification</h2>
<p>Beyond producing more consistent annotations, the comparative approach also proved more efficient. Annotators completed the ranking task in 28.77 seconds per sentence on average, compared to 38.69 seconds for the binary task – nearly 10 seconds faster per sentence.</p><p>“Whilst this is partly expected due to the complex words being pre-selected, the annotator is still required to read and consider the words within context,” explains the paper. “These results suggest that ranking is a more efficient mechanism for collecting complex word annotations that results in a higher annotator reliability than traditional approaches.”</p><p>This efficiency gain could translate to significant time savings when creating large datasets needed for training machine learning models.</p><h2 id="homogeneous-annotator-groups-may-contribute-to-better-agreement">Homogeneous annotator groups may contribute to better agreement</h2>
<p>While the primary focus of the study was comparing binary versus comparative judgments, another interesting finding emerged. Even the binary classification task in this study showed higher agreement (Alpha = 0.496) than previous binary annotation efforts (Alpha = 0.244).</p><p>The researchers suggest this improvement may stem from using a more homogeneous group of annotators who share similar language backgrounds, education levels, and ages. When people have similar reference points for judging complexity, they’re more likely to agree.</p><p>“This supports the case that the concept of word complexity, and thus the level of agreement, is aligned between individuals that share a common background,” notes the paper.</p><h2 id="comparative-judgments-could-improve-machine-learning-for-subjective-concepts">Comparative judgments could improve machine learning for subjective concepts</h2>
<p>The implications of this research extend beyond complex word identification. Many machine learning tasks involve subjective human experiences that exist on a continuum rather than in distinct categories – things like humor, emotion, or aesthetic quality.</p><p>“Comparative labels are used relatively rarely in ML research at present, but our results suggest that this may be a more reliable basis for training such models in future, especially where the phenomenon to be modelled relies on human experience,” the researchers conclude.</p><p>Another advantage of the ranking approach is that it can generate more labeled data without additional annotation effort. When words are ranked by complexity, relationships between all words in the ranking can be inferred, providing more training signal for machine learning models.</p><p>It should be noted that this study has some limitations. The sample size of 30 annotators was relatively small, and the experiment focused on a homogeneous group of native English speakers with graduate degrees. Future research should explore whether similar results hold for other demographic groups and annotation tasks.</p><p>Nevertheless, the findings suggest a promising direction for improving the quality and efficiency of human annotations for machine learning, particularly for subjective concepts that resist simple binary classification.</p><h2 id="references">References</h2>
<p>Gooding, S., Kochmar, E., Sarkar, A., &amp; Blackwell, A. (2019). Comparative judgments are more consistent than binary classification for labelling word complexity. In Proceedings of the 13th Linguistic Annotation Workshop (pp. 208–214). Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/W19-4024">https://doi.org/10.18653/v1/W19-4024</a></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Somewhere Around That Number: How Spreadsheet Users Navigate the Murky Waters of Uncertainty</title>
        <author>
            <name>TAP Communications</name>
        </author>
        <link href="https://advaitsarkar.github.io/autoblog/somewhere-around-that-number-how-spreadsheet-users-navigate-the-murky-waters-of-uncertainty.html"/>
        <id>https://advaitsarkar.github.io/autoblog/somewhere-around-that-number-how-spreadsheet-users-navigate-the-murky-waters-of-uncertainty.html</id>

        <updated>2025-04-16T13:44:05+01:00</updated>
            <summary>
                <![CDATA[
                    Abstract This article examines how people handle uncertainty in spreadsheets based on the findings of an interview study with 11&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h2 id="abstract">Abstract</h2>
<p>This article examines how people handle uncertainty in spreadsheets based on the findings of an interview study with 11 spreadsheet users from various professional domains. The study reveals that spreadsheets serve multiple roles beyond calculation, functioning as databases, templates, notepads, and exploration tools, with each role influencing how users manage uncertainty. </p><p>Reference: Borghouts, J., Gordon, A. D., Sarkar, A., O’Hara, K. P., &amp; Toronto, N. (2019). Somewhere around that number: An interview study of how spreadsheet users manage uncertainty. arXiv. <a href="https://arxiv.org/abs/1905.13072">https://arxiv.org/abs/1905.13072</a></p><h2 id="spreadsheets-are-the-swiss-army-knife-of-uncertainty-management">Spreadsheets are the Swiss Army knife of uncertainty management</h2>
<p>In the messy landscape of modern work, uncertainty lurks everywhere. The sales projection that might be off by 20%. The project timeline with tasks of unknown duration. The dataset with gaps and errors. When facing these challenges, professionals across industries reach for the same tool: the spreadsheet.</p><p>“Data uncertainty is ubiquitous in various settings,” notes the research paper at the heart of this discussion. “Academics may deal with noise and missing data in their datasets, managers make business decisions based on projected sales data, and project leaders adapt schedules based on estimated workload.”</p><p>But how exactly do people use spreadsheets to wrangle this uncertainty in their daily work? This question drove a team of researchers to interview 11 spreadsheet users from fields ranging from finance to academic research.</p><p>What they discovered was that the humble spreadsheet serves as far more than just a calculation tool. It functions as a database, template, notepad, and exploration tool, with each role influencing how users approach uncertainty. This multi-faceted functionality helps explain why, despite sophisticated alternatives, spreadsheets remain deeply embedded in organizational workflows when dealing with uncertain information.</p><h2 id="uncertainty-comes-in-many-flavors-that-spreadsheet-users-must-taste">Uncertainty comes in many flavors that spreadsheet users must taste</h2>
<p>The study identified several types of uncertainty that spreadsheet users regularly encounter. The most common? Estimates, those approximated values where the precise figure remains unknown. As one participant put it: “We’re talking about the future. We don’t know exactly what’s going to happen. All we can do is make best estimates.”</p><p>Other uncertainty types included missing data (values not recorded in datasets), errors (incorrect values or error messages), dynamic data (information that changes over time), untraceable data (information with unknown sources), and unfindable data (information that users couldn’t locate within their spreadsheets).</p><p>These uncertainty types don’t exist in isolation. They often coexist within the same spreadsheet, creating a complex ecosystem of certainty and doubt that users must navigate.</p><h2 id="the-spreadsheet-grid-becomes-a-visual-canvas-for-mapping-uncertainty">The spreadsheet grid becomes a visual canvas for mapping uncertainty</h2>
<p>One of the most interesting findings concerns how users visually represent uncertainty within the grid-based framework of spreadsheets. Since spreadsheets treat uncertain and certain values identically as deterministic numbers, users developed creative workarounds.</p><p>Some participants used color coding to indicate uncertainty levels: “Instead of having to scroll through each cell and looking at the actual value, you can tell it to conditionally format to green is low, red is high, and it’ll pick up quite easily where things might look a bit funny,” explained one participant.</p><p>Others distributed possible values across multiple cells for visual comparison or used formulas rather than static values to indicate uncertainty. One accountant used a system of green, yellow, and red to communicate reliability to clients, noting: “There’s a visceral immediacy to it, it’s traffic lights.”</p><p>The spatial properties of spreadsheets played a crucial role in uncertainty management. The grid layout allowed users to juxtapose different scenarios side by side for visual comparison, while formulas enabled them to define and explore relationships between variables.</p><h2 id="from-analysis-to-decision-making-uncertainty-gets-compressed-along-the-way">From analysis to decision-making, uncertainty gets compressed along the way</h2>
<p>An important pattern emerged regarding how uncertainty transforms as data moves through organizational workflows. Participants described a journey from raw, uncertain data to simplified presentations for decision-makers.</p><p>“The more senior you are, the more you want an answer, either yes or no, there’s not really a thing in-between,” noted a bank accountant.</p><p>The research identified three stages in this journey. First, uncertain data was collected and prepared for analysis. Next, users aimed to understand the level of uncertainty through scenario comparison and discussions with colleagues. Finally, uncertain data was transformed into simplified versions for decision-makers.</p><p>This compression of uncertainty from analysis to presentation wasn’t about hiding complexity but transforming it into a form that enabled action: “You will do all of the background analysis, and you walk in there with a simple decision for them. Come in there with eight, and they’ll look at you and go, ‘Well I’m not doing that, that’s your job to filter that.’”</p><h2 id="trust-trumps-accuracy-when-communicating-uncertainty">Trust trumps accuracy when communicating uncertainty</h2>
<p>When presenting uncertainty to others, participants prioritized building trust over conveying complete accuracy. Depending on the domain and audience, showing uncertainty could either increase or decrease trust.</p><p>“The only way to be honest about it is to put the uncertainty in there,” said one participant who presented climate change predictions to policy makers. Yet another participant who presented financial forecasts noted that uncertainty “shows ambiguity, and people just don’t like that.”</p><p>Spreadsheets played a vital role in building this trust by helping users construct narratives around uncertain data. The process of creating and manipulating spreadsheets improved users’ understanding of their data, which in turn boosted their confidence when presenting results to others.</p><h2 id="spreadsheet-limitations-create-opportunities-for-better-uncertainty-tools">Spreadsheet limitations create opportunities for better uncertainty tools</h2>
<p>The study revealed several limitations in how current spreadsheets support uncertainty management. For instance, spreadsheets force users to input one value per cell, treating uncertain values as discrete rather than connected. Users also struggled to compress comprehensive spreadsheets into formats suitable for decision-makers.</p><p>These limitations point toward opportunities for improved spreadsheet functionality. The researchers suggest potential directions like creating separate analysis and presentation layers, automatically highlighting uncertain data values, and enabling direct input of uncertain values as distributions rather than single points.</p><p>It should be noted that the study has limitations. All participants were male and used spreadsheets for work purposes, which may have influenced their strategies. The sample size of 11 participants also limits the generalizability of the findings.</p><p>Nevertheless, the research provides valuable insights into how the material features of spreadsheets both enable and constrain uncertainty work. By understanding these dynamics, we can reimagine how spreadsheet tools might offer richer support for handling uncertainty in our increasingly unpredictable world.</p><h2 id="references">References</h2>
<p>Borghouts, J., Gordon, A. D., Sarkar, A., O’Hara, K. P., &amp; Toronto, N. (2019). Somewhere around that number: An interview study of how spreadsheet users manage uncertainty. arXiv. <a href="https://arxiv.org/abs/1905.13072">https://arxiv.org/abs/1905.13072</a></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>When Technology Asks &quot;What Do You Want?&quot;: Rule-Based Programming vs. Reinforcement Learning in System Personalization</title>
        <author>
            <name>TAP Communications</name>
        </author>
        <link href="https://advaitsarkar.github.io/autoblog/when-technology-asks-what-do-you-want-rule-based-programming-vs-reinforcement-learning-in-system-personalization.html"/>
        <id>https://advaitsarkar.github.io/autoblog/when-technology-asks-what-do-you-want-rule-based-programming-vs-reinforcement-learning-in-system-personalization.html</id>

        <updated>2025-04-16T13:35:18+01:00</updated>
            <summary>
                <![CDATA[
                    Abstract This article examines the trade-offs between two approaches to personalizing technology systems: explicit rule-based programming versus reinforcement learning through&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h2 id="abstract">Abstract</h2>
<p>This article examines the trade-offs between two approaches to personalizing technology systems: explicit rule-based programming versus reinforcement learning through feedback. The results break down a comparative user study that investigated how people respond to and interact with these different personalization methods.</p><p><strong>Reference</strong>: Liu, R., Sarkar, A., Solovey, E., &amp; Tschiatschek, S. (2019, March). Evaluating rule-based programming and reinforcement learning for personalising an intelligent system. In 2nd Workshop on Explainable Smart Systems (ExSS 2019), held in conjunction with ACM Intelligent User Interfaces (IUI 2019).</p><h2 id="smart-technology-personalization-faces-a-fundamental-user-experience-dilemma">Smart technology personalization faces a fundamental user experience dilemma</h2>
<p>Imagine walking into a meeting room late. You’re a person who is blind or low vision or joining remotely without video. Everyone else immediately sees who’s there, what they’re doing, and the general vibe of the room. You don’t. This information gap can significantly impact your ability to participate effectively.</p><p>Now imagine having a smart device that could tell you exactly what’s happening in that room - but first, you need to teach it what information matters most to you. Would you prefer to write specific rules for what you want to know (“If someone is speaking, tell me who they are”), or would you rather just give thumbs up or down feedback as the system makes guesses about what might be useful?</p><p>This seemingly simple design question sits at the heart of how we interact with increasingly intelligent technologies.</p><p>“Many intelligent systems can be personalised by end-users to suit their specific needs. However, the interface for personalisation often trades off the degree of personalisation achievable with time, effort, and level of expertise required by the user,” notes the paper published in the Proceedings of ACM IUI 2019 Workshops.</p><h2 id="the-study-created-a-simulated-meeting-environment-to-test-personalization-methods">The study created a simulated meeting environment to test personalization methods</h2>
<p>To explore this question systematically, the research team built a meeting simulator. This generated random meetings with 3-8 attendees, each with specific attributes like their name, pose (sitting/standing), activity (speaking/typing/listening), where they were looking, and their location in the room. </p><p>For the study, 15 participants were asked to personalize a notification system that would provide only the information they cared about when entering a meeting. Each person tried two different approaches: rule-based programming and reinforcement learning.</p><p>With rule-based programming, participants directly specified what information they wanted through if-then rules. For example: “When there is an attendee whose activity is speaking, tell me the name and activity for attendees whose activity is speaking.”</p><p>With reinforcement learning, participants simply gave binary yes/no feedback about whether each notification was useful. Behind the scenes, an AI system learned from this feedback using a neural network to predict what information would be valuable.</p><h2 id="rule-based-programming-produced-higher-satisfaction-but-required-more-understanding">Rule-based programming produced higher satisfaction but required more understanding</h2>
<p>Participants reported significantly lower cognitive load and higher satisfaction when using rule-based programming compared to reinforcement learning. With rules, people felt more in control. As one participant put it: “Of course I am satisfied, because I chose the rules myself.”</p><p>However, rule-based programming wasn’t without challenges. Some participants struggled to understand the filtered information resulting from their rules. One participant expressed frustration: “I want to know when people are speaking, whether people are listening and what they are doing now, this includes much more information… When I told you to use the rules, it lost too much information.”</p><p>Others found it difficult to maintain multiple rules and understand how they worked together. “So all of these rules are stacking up?” asked one participant. Another wondered: “Okay, the last one was very short, did some of these [rules] override each other?”</p><h2 id="reinforcement-learning-proved-easier-but-slower-and-less-transparent">Reinforcement learning proved easier but slower and less transparent</h2>
<p>Reinforcement learning presented a different set of challenges. Many participants found it difficult to provide simple yes/no feedback when their preferences were more nuanced. “If I am okay with that, but if I need some new information, should I press yes or no?” asked one participant.</p><p>Participants also worried about giving inconsistent feedback, feeling responsible if the system didn’t learn properly. “It is hard for me to give the feedback. At the beginning, I thought this information is good to understand this meeting. but then after training for a while, I begin to notice that some information is too much for me,” explained one participant.</p><p>Perhaps most notably, participants expressed uncertainty about what the system was capable of learning and what would happen after training. “Does the training, for the whole training period, give me all the options?” asked one participant. Another simply wondered: “So what is its conclusion?”</p><h2 id="the-ideal-personalization-system-might-combine-both-approaches">The ideal personalization system might combine both approaches</h2>
<p>Interestingly, the majority of participants expressed a preference for a hybrid approach. They wanted the control and transparency of rule-based programming combined with the learning capabilities of reinforcement learning.</p><p>“For people who wanted a combination of the two approaches, all of them expressed a similar idea of being able to control the system’s behaviour by entering or editing rules, while also using a pre-training phase with the reinforcement learning model to help them figure out what they want or to suggest rules,” the paper reports.</p><p>This suggests that the ideal personalization interface might use reinforcement learning to help users discover their preferences and generate suggested rules, which users could then refine directly.</p><h2 id="the-findings-reveal-important-design-considerations-for-personalized-technology">The findings reveal important design considerations for personalized technology</h2>
<p>The study highlights three critical design considerations for personalization interfaces:</p><p>First, systems need to clearly communicate their capabilities. Users struggled to understand what kinds of rules they could create or what preferences the reinforcement learning system could learn. This limited their ability to form and express preferences effectively.</p><p>Second, interfaces need to support flexible preference expression. Binary feedback proved too restrictive for many participants, while rule creation was challenging for others. A hybrid approach could offer the best of both worlds.</p><p>Third, systems should help users develop accurate mental models. Participants became confused when managing multiple rules or when trying to understand what the reinforcement learning system had learned. Providing context and explanations could help users build better mental models of how the system works.</p><h2 id="notes-on-generalizability">Notes on generalizability</h2>
<p>The study has limitations. The sample size of 15 participants is relatively small, and the laboratory setting with simulated meetings may not fully capture real-world complexity. Additionally, the researcher helped participants navigate the rule-based interface, which likely influenced the cognitive load measurements.</p><p>This study examined a specific personalization scenario (meeting notifications). Different contexts might yield different results depending on the complexity of user preferences and the nature of the personalization task.</p><p>The findings nonetheless offer valuable insights into how users experience different personalization approaches, highlighting the potential benefits of combining rule-based control with machine learning assistance.</p><h2 id="references">References</h2>
<p>Liu, R., Sarkar, A., Solovey, E., &amp; Tschiatschek, S. (2019, March). Evaluating rule-based programming and reinforcement learning for personalising an intelligent system. In 2nd Workshop on Explainable Smart Systems (ExSS 2019), held in conjunction with ACM Intelligent User Interfaces (IUI 2019).</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Dual View Spreadsheets Could Help You Make Fewer Errors and Work Faster: Learn About Calculation View</title>
        <author>
            <name>TAP Communications</name>
        </author>
        <link href="https://advaitsarkar.github.io/autoblog/dual-view-spreadsheets-could-help-you-make-fewer-errors-and-work-faster.html"/>
        <id>https://advaitsarkar.github.io/autoblog/dual-view-spreadsheets-could-help-you-make-fewer-errors-and-work-faster.html</id>

        <updated>2025-04-14T11:19:12+01:00</updated>
            <summary>
                <![CDATA[
                    Abstract This article breaks down the results of a scientific paper that explores how adding a textual programming interface to&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h2 id="abstract">Abstract</h2>
<p>This article breaks down the results of a scientific paper that explores how adding a textual programming interface to spreadsheets can reduce errors and increase efficiency. The researchers designed a feature called “Calculation View” that displays formulas in a text-based format alongside the traditional grid, allowing users to work with spreadsheets at a higher level of abstraction. The study found that this approach significantly reduced task completion time and cognitive load without negatively affecting user confidence.</p><p>Reference: Sarkar, A., Gordon, A. D., Jones, S. P., &amp; Toronto, N. (2018, October). Calculation View: Multiple-representation editing in spreadsheets. In 2018 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC) (pp. 85–93). IEEE. <a href="https://doi.org/10.1109/VLHCC.2018.8506584">https://doi.org/10.1109/VLHCC.2018.8506584</a></p><h2 id="why-spreadsheets-are-both-wonderful-and-difficult">Why Spreadsheets Are Both Wonderful and Difficult</h2>
<p>Spreadsheets are ubiquitous in modern workplaces. They’re flexible, powerful, and accessible to almost anyone with a computer. But they can also be error-prone.</p><p>The problem is fundamental to how spreadsheets work. “Spreadsheets excel at showing data, while hiding computation,” the paper notes. When you look at a spreadsheet, you see numbers and charts, but the formulas that generate those results are hidden from view. To see how a calculation works, you need to click on each cell individually and examine its formula in a tiny box at the top of the screen.</p><p>This invisibility of computational structure makes spreadsheets challenging to understand, debug, and maintain. And these aren’t just minor inconveniences. Spreadsheet errors have real-world consequences, from financial miscalculations to flawed research findings.</p><h2 id="the-hidden-world-of-spreadsheet-programming">The Hidden World of Spreadsheet Programming</h2>
<p>Most people don’t think of themselves as programmers when they use Excel. But they are.</p><p>Every time someone writes a formula like <code>&quot;=SUM(A1:A10)&quot;</code> or <code>&quot;=B2*0.15&quot;</code>, they’re creating code. The problem is that this code is scattered across potentially thousands of cells, with no easy way to view it all at once or understand the relationships between formulas.</p><p>Consider a common spreadsheet pattern: a column of data with several columns of calculations based on that data:</p><pre><code>Data   Formula 1   Formula 2   ...   Formula k
d1     F1(d1)      F2(d1)      ...   Fk(d1)
d2     F1(d2)      F2(d2)      ...   Fk(d2)
...    ...         ...         ...   ...
dn     F1(dn)      F2(dn)      ...   Fk(dn)
</code></pre>
<p>In this example, there are only k distinct formulas (one per column), but they’re duplicated across n rows. Editing these formulas becomes tedious and error-prone because you need to make sure your changes are applied consistently across potentially hundreds or thousands of cells.</p><p>Another major issue is that cell references like “A1” or “B2” are not helpful as variable names. They tell you nothing about what the cell represents. Is A1 a tax rate? A growth percentage? Without context, spreadsheet formulas become cryptic.</p><h2 id="calculation-view-makes-spreadsheet-code-visible-and-editable">Calculation View Makes Spreadsheet Code Visible and Editable</h2>
<p>What if spreadsheets had an alternative view optimized for working with formulas rather than data? This is the core idea behind Calculation View (CV).</p><p>CV displays a text-based representation of a spreadsheet’s formulas alongside the traditional grid. Edits in either view are immediately reflected in the other. This approach preserves all the benefits of the familiar grid interface while adding new capabilities for working with formulas.</p><p>The most powerful feature of CV is range assignment. Instead of typing a formula in one cell and then copying it down or across, you can write:</p><pre><code>B1:B10 = SQRT(A1)
</code></pre>
<p>This single line assigns the formula =SQRT(A1) to cell B1 and copies it down through B10, automatically adjusting cell references in the same way Excel’s copy-paste or drag-fill would. But it’s much more explicit about what’s happening.</p><p>CV also makes it easy to give meaningful names to cells or ranges:</p><pre><code>TaxRate A1 = 0.01
</code></pre>
<p>This puts the value 0.01 in cell A1 and gives it the name “TaxRate”. Other formulas can then refer to “TaxRate” instead of “A1”, making them more readable and less prone to errors.</p><h2 id="multiple-representations-help-users-work-at-different-levels-of-abstraction">Multiple Representations Help Users Work at Different Levels of Abstraction</h2>
<p>The core principle behind CV is known as “multiple representations,” an approach that has been successful in educational contexts. By showing the same information in different ways, users can better understand complex concepts and choose the representation that works best for their current task.</p><p>“By offering multiple representations of the same core object (in our case, the program exemplified by the spreadsheet), we can help the user learn to move fluently between different levels of abstraction, choosing the abstraction appropriate for the task at hand,” the paper explains.</p><p>This is particularly valuable in spreadsheets, where users often need to switch between thinking about individual values and thinking about patterns of calculation across many rows or columns.</p><h2 id="users-completed-tasks-faster-and-with-less-mental-effort">Users Completed Tasks Faster and With Less Mental Effort</h2>
<p>Does adding a second view actually help users? The study tested this question with 22 participants who performed spreadsheet authoring and debugging tasks both with and without CV.</p><p>The results were clear: with CV, participants completed authoring tasks 37% faster (median) and debugging tasks 41% faster (median). They also reported lower cognitive load, particularly in terms of frustration.</p><p>Interestingly, the benefits of CV applied to both experienced and novice spreadsheet users, though in slightly different ways. Less experienced users saw greater speed improvements for authoring tasks, while experienced users were more likely to notice a reduction in physical demand (likely because they were already using various shortcuts and techniques to minimize the physical effort of operations like drag-filling).</p><p>It’s worth noting a limitation of the study: the tasks were fairly constrained, focusing specifically on formula creation, copying, and debugging, rather than the full range of spreadsheet activities. Additional research would be needed to determine whether these benefits extend to all types of spreadsheet work.</p><h2 id="the-future-of-spreadsheet-interfaces-could-involve-multiple-views">The Future of Spreadsheet Interfaces Could Involve Multiple Views</h2>
<p>CV represents just a first step in exploring how multiple representations might improve spreadsheet usability. The paper suggests several potential extensions, such as supporting non-rectangular ranges, sequence generation, and enhanced programming tools for experts.</p><p>Different representations could also be developed for different purposes. Beyond textual code, spreadsheets could potentially be viewed as block-based programs (similar to Scratch) or flow charts that emphasize data dependencies.</p><p>By expanding the ways users can interact with spreadsheets, these tools could make complex data work more accessible and reliable. The traditional grid isn’t going anywhere, but complementary views could help us avoid the pitfalls that have plagued spreadsheets for decades.</p><h2 id="references">References</h2>
<p>Sarkar, A., Gordon, A. D., Jones, S. P., &amp; Toronto, N. (2018, October). Calculation View: Multiple-representation editing in spreadsheets. In 2018 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC) (pp. 85–93). IEEE. <a href="https://doi.org/10.1109/VLHCC.2018.8506584">https://doi.org/10.1109/VLHCC.2018.8506584</a></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>How Spreadsheet Users Really Learn Excel: The Informal, Social Path to Spreadsheet Expertise</title>
        <author>
            <name>TAP Communications</name>
        </author>
        <link href="https://advaitsarkar.github.io/autoblog/how-spreadsheet-users-really-learn-excel-the-informal-social-path-to-spreadsheet-expertise.html"/>
        <id>https://advaitsarkar.github.io/autoblog/how-spreadsheet-users-really-learn-excel-the-informal-social-path-to-spreadsheet-expertise.html</id>

        <updated>2025-04-14T11:11:04+01:00</updated>
            <summary>
                <![CDATA[
                    Abstract This article breaks down the findings of a research paper that investigated how people actually learn to use spreadsheet&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h2 id="abstract">Abstract</h2>
<p>This article breaks down the findings of a research paper that investigated how people actually learn to use spreadsheet software like Microsoft Excel. The study reveals that most Excel learning happens informally through social interactions rather than formal training. The paper analyzed interviews with seven participants of varying expertise levels to understand the spreadsheet learning process. </p><p>Reference: Sarkar, A., &amp; Gordon, A. D. (2018, September). How do people learn to use spreadsheets? (Work in progress). In Proceedings of the 29th Annual Conference of the Psychology of Programming Interest Group (PPIG 2018) (pp. 28–35).</p><h2 id="spreadsheet-learning-rarely-happens-in-classrooms">Spreadsheet Learning Rarely Happens in Classrooms</h2>
<p>Forget formal training courses and thick Excel manuals. The reality of how most people learn spreadsheet skills is far more organic and messy. According to research, Excel users typically don’t learn through structured training but instead through a combination of necessity, observation, and social connections.</p><p>“I never did a course in Excel. I’ve never taken a formal learning in Excel,” admitted one study participant who works as a small company accountant. This sentiment was echoed across participants of various expertise levels, from occasional users to sophisticated developers who create custom spreadsheet add-ins.</p><p>The formal documentation that comes with spreadsheet software often goes unused. Users reported finding built-in help features inadequate for discovering new functions. As one examination marking overseer put it: “I don’t find help in [the tool] particularly useful as a way of discovering a function. It’s very useful when you’ve worked out what function, to understand how it works. But I don’t find it particularly useful for finding the right function to use.”</p><h2 id="learning-spreadsheets-is-driven-by-immediate-problems-not-abstract-interest">Learning Spreadsheets Is Driven by Immediate Problems, Not Abstract Interest</h2>
<p>Most spreadsheet learning is opportunistic. Users typically acquire new skills when they encounter a specific problem that demands a solution beyond their current knowledge base.</p><p>“I know what I know how to use because it’s what I’ve needed,” explained one study participant. “Effectively, I’ve learnt the functions as I’ve come across a need to use them, rather than just learning things abstractly.”</p><p>This problem-driven approach creates an interesting learning pattern. Rather than systematically working through tutorials, users develop their skillset in an uneven, almost haphazard way based on what challenges they’ve faced. Someone might be proficient with complex financial functions but completely unaware of basic data visualization techniques simply because they’ve never needed to create charts.</p><p>A professional accountant in the study described a situation where necessity forced learning: “There was this part of the APT (arbitrage pricing theory) that required a normal distribution and there was no function in Excel to do that. And given an obstacle, I then had to get around it, because it was a University deliverable. Given that obstacle, many hours were spent beating my head against the glass pane of that Mac trying to work out how to do it, and as a consequence, I learnt Excel.”</p><h2 id="the-excel-guru-effect-how-spreadsheet-knowledge-spreads-through-social-networks">The Excel Guru Effect: How Spreadsheet Knowledge Spreads Through Social Networks</h2>
<p>Perhaps the most notable finding is how critical social connections are for spreadsheet learning. Within organizations, knowledge about Excel features and techniques typically spreads from person to person rather than from documentation to person.</p><p>“I used to have a colleague years ago. He was a real whiz with spreadsheets,” recalled one large company accountant. “Occasionally he would point out ‘oh, you can simplify this by putting this in there’ and I guess subliminally you take these things in.”</p><p>This social learning creates informal networks of expertise within organizations, with certain individuals becoming known as spreadsheet “gurus” who others seek out for help. The learning process resembles an apprenticeship model where novices learn by watching and getting guidance from more experienced users.</p><p>An energy demand modeller explained: “Consultancies work on an apprenticeship model, so there’s usually someone more senior on the project, who will advise… you can access advice from people in your team and other gurus around the company.”</p><p>This social spread of knowledge helps explain why certain Excel techniques become common in particular workplaces while remaining unknown in others. When an influential person within an organization adopts a particular approach, it tends to spread through the office.</p><h2 id="the-feature-adoption-trinity-discovery-expertise-and-attention-investment">The Feature Adoption Trinity: Discovery, Expertise, and Attention Investment</h2>
<p>The research suggests that adopting new Excel features involves three distinct components: discovery, expertise acquisition, and attention investment (a concept describing how users decide whether learning something new is worth the effort).</p><p>Feature discovery often happens when users see the feature being used in someone else’s spreadsheet. As one climate change modeller explained: “So for example at some point there was introduced SUMIFS. I must have just seen that in a spreadsheet somewhere and thought ‘what the hell is that?’ and at some point come back to it and looked at it in help, and decided that was the right thing to do.”</p><p>The visibility of features in shared spreadsheets creates natural learning moments. When users see something unfamiliar in a colleague’s work, it sparks curiosity that can lead to learning. This helps explain why visible features tend to spread more effectively than hidden ones.</p><h2 id="motivation-makes-the-difference-in-excel-mastery">Motivation Makes the Difference in Excel Mastery</h2>
<p>Not all spreadsheet users approach learning the same way. The research identifies a spectrum of intrinsic motivation that significantly impacts how people engage with the software.</p><p>Users with low intrinsic motivation tend to learn passively, picking up techniques only when absolutely necessary or when directly shown by colleagues. They often develop “coping mechanisms” that let them accomplish tasks without learning more efficient methods. For example, they might manually type calculated values rather than learning formulas, or use arithmetic operators instead of functions like SUM.</p><p>In contrast, highly motivated users actively seek out knowledge, often through online forums and experimentation. “I went to those kind of fora, and then largely trial and error,” said one climate change modeller. “So trying it out and putting myself in the developer’s mindset here ‘surely this is how they would have done it’ and you try out something assuming that this is how they’ve done it and see if it works as it’s meant to work.”</p><p>These high-motivation users often approach spreadsheet tasks with an eye toward solving not just the immediate problem but a more general version that will be useful in the future. “And my approach to Excel was always to… on any given task, try and solve the task that was one step more general,” explained one participant.</p><h2 id="limitations-and-calls-for-further-research">Limitations and Calls for Further Research</h2>
<p>While insightful, this research was preliminary, based on interviews with only seven participants. This small sample size limits how confidently these findings can be generalized to the broader population of spreadsheet users. Additionally, the convenience sampling method may have introduced selection bias.</p><p>The gender distribution was also heavily skewed, with only one female participant. Previous research has suggested that gender differences may exist in technology adoption patterns, making this an important area for future research with more representative samples.</p><p>Despite these limitations, the findings align with earlier research on informal learning practices and offer valuable insights for designing spreadsheet features that better match how people actually learn.</p><h2 id="references">References</h2>
<p>Sarkar, A., &amp; Gordon, A. D. (2018, September). How do people learn to use spreadsheets? (Work in progress). In Proceedings of the 29th Annual Conference of the Psychology of Programming Interest Group (PPIG 2018) (pp. 28–35).</p>
            ]]>
        </content>
    </entry>
</feed>
